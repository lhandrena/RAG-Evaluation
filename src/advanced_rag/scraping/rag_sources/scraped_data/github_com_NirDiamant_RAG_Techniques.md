# Source: https://github.com/NirDiamant/RAG_Techniques

# GitHub - NirDiamant/RAG_Techniques: This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.

NirDiamant/RAG_TechniquesPublicSponsorNotificationsYou must be signed in to change notification settingsFork2.5kStar22.5kThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.LicenseView license22.5kstars2.5kforksBranchesTagsActivityStarNotificationsYou must be signed in to change notification settings

NirDiamant/RAG_TechniquesPublicSponsorNotificationsYou must be signed in to change notification settingsFork2.5kStar22.5k

NirDiamant/RAG_TechniquesPublic

NirDiamant/RAG_TechniquesPublic

SponsorNotificationsYou must be signed in to change notification settingsFork2.5kStar22.5k

NotificationsYou must be signed in to change notification settings

This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.LicenseView license22.5kstars2.5kforksBranchesTagsActivityStarNotificationsYou must be signed in to change notification settings

This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.LicenseView license22.5kstars2.5kforksBranchesTagsActivityStarNotificationsYou must be signed in to change notification settings

This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.

22.5kstars2.5kforksBranchesTagsActivity

StarNotificationsYou must be signed in to change notification settings

NotificationsYou must be signed in to change notification settings

NirDiamant/RAG_Techniquesmain1Branch0TagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic SearchAboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repositoryReleasesNo releases publishedSponsor this projectNirDiamantSponsorLearn more about GitHub SponsorsPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.Contributors31+ 17 contributorsLanguagesJupyter Notebook94.9%Python5.1%

# NirDiamant/RAG_Techniques

main1Branch0TagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic SearchAboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repositoryReleasesNo releases publishedSponsor this projectNirDiamantSponsorLearn more about GitHub SponsorsPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.Contributors31+ 17 contributorsLanguagesJupyter Notebook94.9%Python5.1%

main1Branch0TagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic SearchAboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repositoryReleasesNo releases publishedSponsor this projectNirDiamantSponsorLearn more about GitHub SponsorsPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.Contributors31+ 17 contributorsLanguagesJupyter Notebook94.9%Python5.1%

main1Branch0TagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic SearchAboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repositoryReleasesNo releases publishedSponsor this projectNirDiamantSponsorLearn more about GitHub SponsorsPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.Contributors31+ 17 contributorsLanguagesJupyter Notebook94.9%Python5.1%

main1Branch0TagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

main1Branch0TagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

main1Branch0TagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

main1Branch0TagsGo to fileCodeOpen more actions menu

Go to fileCodeOpen more actions menu

Open more actions menu

Open more actions menu

Folders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all filesRepository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

Folders and filesNameNameLast commit messageLast commit dateLatest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details.github.githubadded workflowsSep 11, 2024all_rag_techniquesall_rag_techniquesadded agentic RAGSep 8, 2025all_rag_techniques_runnable_scriptsall_rag_techniques_runnable_scriptsMerge pull request#83from VakeDomen/feature/hypeApr 1, 2025datadataupdated codeFeb 2, 2025evaluationevaluationproject updateJul 27, 2025imagesimagesupdated readmeOct 8, 2025teststestsupdated codeFeb 2, 2025.gitignore.gitignoreadded substack logo in readmeOct 25, 2024CONTRIBUTING.mdCONTRIBUTING.mdproject updateJul 27, 2025LICENSELICENSEupdated LICENSEOct 3, 2024README.mdREADME.mdupdatedOct 8, 2025helper_functions.pyhelper_functions.pyupdated codeFeb 2, 2025View all files

Latest commitNirDiamantupdatedOct 8, 2025b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details

NirDiamantupdatedOct 8, 2025

b9617dfÂ·Oct 8, 2025History422 CommitsOpen commit details

History422 CommitsOpen commit details

all_rag_techniques_runnable_scripts

all_rag_techniques_runnable_scripts

all_rag_techniques_runnable_scripts

all_rag_techniques_runnable_scripts

all_rag_techniques_runnable_scripts

all_rag_techniques_runnable_scripts

all_rag_techniques_runnable_scripts

all_rag_techniques_runnable_scripts

Merge pull request#83from VakeDomen/feature/hype

Merge pull request#83from VakeDomen/feature/hype

added substack logo in readme

added substack logo in readme

Repository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

Repository files navigationğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

Repository files navigation

## Repository files navigation

ğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!Sponsors â¤ï¸We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.Company SponsorsIndividual SponsorsAdvanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.ğŸ“« Stay Updated!ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!IntroductionRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.Related ProjectsğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.A Community-Driven Knowledge HubThis repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤Educational AI SubredditRAG Techniques Discord CommunityWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.Key FeaturesğŸ§  State-of-the-art RAG enhancementsğŸ“š Comprehensive documentation for each techniqueğŸ› ï¸ Practical implementation guidelinesğŸŒŸ Regular updates with the latest advancementsAdvanced TechniquesExplore our extensive list of cutting-edge RAG techniques:#CategoryTechniqueView1â­ Key CollaborationAgentic RAG with Contextual AI2Foundational ğŸŒ±Basic RAG3Foundational ğŸŒ±RAG with CSV Files4Foundational ğŸŒ±Reliable RAG5Foundational ğŸŒ±Optimizing Chunk Sizes6Foundational ğŸŒ±Proposition Chunking7Query Enhancement ğŸ”Query Transformations8Query Enhancement ğŸ”HyDE (Hypothetical Document Embedding)9Query Enhancement ğŸ”HyPE (Hypothetical Prompt Embedding)10Context Enrichment ğŸ“šContextual Chunk Headers11Context Enrichment ğŸ“šRelevant Segment Extraction12Context Enrichment ğŸ“šContext Window Enhancement13Context Enrichment ğŸ“šSemantic Chunking14Context Enrichment ğŸ“šContextual Compression15Context Enrichment ğŸ“šDocument Augmentation16Advanced Retrieval ğŸš€Fusion Retrieval17Advanced Retrieval ğŸš€Reranking18Advanced Retrieval ğŸš€Multi-faceted Filtering19Advanced Retrieval ğŸš€Hierarchical Indices20Advanced Retrieval ğŸš€Ensemble Retrieval21Advanced Retrieval ğŸš€Dartboard Retrieval22Advanced Retrieval ğŸš€Multi-modal RAG with Captioning23Iterative Techniques ğŸ”Retrieval with Feedback Loop24Iterative Techniques ğŸ”Adaptive Retrieval25Iterative Retrieval ğŸ”„Iterative Retrieval26Evaluation ğŸ“ŠDeepEval27Evaluation ğŸ“ŠGroUSE28Explainability ğŸ”¬Explainable Retrieval29Advanced Architecture ğŸ—ï¸Graph RAG with LangChain30Advanced Architecture ğŸ—ï¸Microsoft GraphRAG31Advanced Architecture ğŸ—ï¸RAPTOR32Advanced Architecture ğŸ—ï¸Self-RAG33Advanced Architecture ğŸ—ï¸Corrective RAG (CRAG)34Special Technique ğŸŒŸSophisticated Controllable AgentğŸŒ± Foundational RAG TechniquesSimple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.Additional Resources ğŸ“šThe Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.ğŸ” Query EnhancementQuery Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.ğŸ“š Context and Content EnrichmentHypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.Context Enrichment Techniques ğŸ“LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.Implementation ğŸ› ï¸Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.Semantic Chunking ğŸ§ LangChain:Runnable ScriptOverview ğŸ”Dividing documents based on semantic coherence rather than fixed sizes.Implementation ğŸ› ï¸Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.Additional Resources ğŸ“šSemantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.Contextual Compression ğŸ—œï¸LangChain:Runnable ScriptOverview ğŸ”Compressing retrieved information while preserving query-relevant content.Implementation ğŸ› ï¸Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.Document Augmentation through Question Generation for Enhanced RetrievalLangChain:Runnable ScriptOverview ğŸ”This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.Implementation ğŸ› ï¸Use an LLM to augment text dataset with all possible questions that can be asked to each document.ğŸš€ Advanced Retrieval MethodsFusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.ğŸ” Iterative and Adaptive TechniquesRetrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.ğŸ“Š EvaluationDeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.ğŸ”¬ Explainability and TransparencyExplainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.ğŸ—ï¸ Advanced ArchitecturesAgentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performanceGraph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationshipsKnowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.ğŸŒŸ Special Advanced Technique ğŸŒŸSophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.Getting StartedTo begin implementing these advanced RAG techniques in your projects:Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.gitNavigate to the technique you're interested in:cd all_rag_techniques/technique-nameFollow the detailed implementation guide in each technique's directory.ContributingWe welcome contributions from the community! If you have a new technique or improvement to suggest:Fork the repositoryCreate your feature branch:git checkout -b feature/AmazingFeatureCommit your changes:git commit -m 'Add some AmazingFeature'Push to the branch:git push origin feature/AmazingFeatureOpen a pull requestContributorsLicenseThis project is licensed under a custom non-commercial license - see theLICENSEfile for details.â­ï¸ If you find this repository helpful, please consider giving it a star!Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

ğŸŒŸSupport This Project:Your sponsorship fuels innovation in RAG technologies.Become a sponsorto help maintain and expand this valuable resource!

We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.

Advanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€

# Advanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€

Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.

ğŸš€Cutting-edgeUpdatesğŸ’¡ExpertInsightsğŸ¯Top 0.1%ContentJoin over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!

Join over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!

Retrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.

Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.

ğŸš€ Level up with myAgents Towards Productionrepository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you're serious about shipping agents to production.

ğŸ¤– Explore myGenAI Agents Repositoryto discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.

ğŸ–‹ï¸ Check out myPrompt Engineering Techniques guidefor a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.

A Community-Driven Knowledge Hub

## A Community-Driven Knowledge Hub

This repository grows stronger with your contributions!Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤

Educational AI Subreddit

RAG Techniques Discord Community

Whether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to ourCONTRIBUTING.mdfile. Let's advance RAG technology together!

ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free toconnect on LinkedIn.

ğŸ§  State-of-the-art RAG enhancements

ğŸ“š Comprehensive documentation for each technique

ğŸ› ï¸ Practical implementation guidelines

ğŸŒŸ Regular updates with the latest advancements

Explore our extensive list of cutting-edge RAG techniques:

ğŸŒ± Foundational RAG Techniques

### ğŸŒ± Foundational RAG Techniques

Simple RAG ğŸŒ±LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Introducing basic RAG techniques ideal for newcomers.Implementation ğŸ› ï¸Start with basic retrieval queries and integrate incremental learning mechanisms.

Introducing basic RAG techniques ideal for newcomers.

Start with basic retrieval queries and integrate incremental learning mechanisms.

Simple RAG using a CSV file ğŸ§©LangChain:LlamaIndex:Overview ğŸ”Introducing basic RAG using CSV files.Implementation ğŸ› ï¸This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.

Simple RAG using a CSV file ğŸ§©

Introducing basic RAG using CSV files.

This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.

Reliable RAG ğŸ·ï¸:Overview ğŸ”Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.Implementation ğŸ› ï¸Check for retrieved document relevancy and highlight the segment of docs used for answering.

Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.

Check for retrieved document relevancy and highlight the segment of docs used for answering.

Choose Chunk Size ğŸ“LangChain:Runnable ScriptOverview ğŸ”Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.Implementation ğŸ› ï¸Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.

Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.

Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.

Proposition Chunking â›“ï¸â€ğŸ’¥:Overview ğŸ”Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).Implementation ğŸ› ï¸ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.

Proposition Chunking â›“ï¸â€ğŸ’¥:

Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).

ğŸ’ªProposition Generation:The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.

âœ…Quality Checking:The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.

Additional Resources ğŸ“š

#### Additional Resources ğŸ“š

The Propositions Method: Enhancing Information Retrieval for AI Systems- A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.

Query Transformations ğŸ”„LangChain:Runnable ScriptOverview ğŸ”Modifying and expanding queries to improve retrieval effectiveness.Implementation ğŸ› ï¸âœï¸Query Rewriting:Reformulate queries to improve retrieval.ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.

Query Transformations ğŸ”„

Modifying and expanding queries to improve retrieval effectiveness.

âœï¸Query Rewriting:Reformulate queries to improve retrieval.

ğŸ”™Step-back Prompting:Generate broader queries for better context retrieval.

ğŸ§©Sub-query Decomposition:Break complex queries into simpler sub-queries.

Hypothetical Questions (HyDE Approach) â“LangChain:Runnable ScriptOverview ğŸ”Generating hypothetical questions to improve alignment between queries and data.Implementation ğŸ› ï¸Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.Additional Resources ğŸ“šHyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.

Hypothetical Questions (HyDE Approach) â“

Generating hypothetical questions to improve alignment between queries and data.

Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.

Additional Resources ğŸ“š

#### Additional Resources ğŸ“š

HyDE: Exploring Hypothetical Document Embeddings for AI Retrieval- A short blog post explaining this method clearly.

ğŸ“š Context and Content Enrichment

### ğŸ“š Context and Content Enrichment

Hypothetical Prompt Embeddings (HyPE) â“ğŸš€LangChain:Runnable ScriptOverview ğŸ”HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.Implementation ğŸ› ï¸ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.Additional Resources ğŸ“šPreprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.

Hypothetical Prompt Embeddings (HyPE) â“ğŸš€

HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval thatprecomputes hypothetical prompts at the indexing stage, but inseting the chunk in their place. This transforms retrieval into aquestion-question matching task. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead whileimproving retrieval alignment.

ğŸ“–Precomputed Questions:Instead of embedding document chunks, HyPEgenerates multiple hypothetical queries per chunkat indexing time.

ğŸ”Question-Question Matching:User queries are matched against stored hypothetical questions, leading tobetter retrieval alignment.

âš¡No Runtime Overhead:Unlike HyDE, HyPE doesnot require LLM calls at query time, making retrievalfaster and cheaper.

ğŸ“ˆHigher Precision & Recall:Improves retrievalcontext precision by up to 42 percentage pointsandclaim recall by up to 45 percentage points.

Additional Resources ğŸ“š

#### Additional Resources ğŸ“š

Preprint: Hypothetical Prompt Embeddings (HyPE)- Research paper detailing the method, evaluation, and benchmarks.

Contextual Chunk Headers ğŸ·ï¸:Overview ğŸ”Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.Implementation ğŸ› ï¸Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.Additional Resources ğŸ“šdsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)

Contextual Chunk Headers ğŸ·ï¸:

Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.

Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.

Additional Resources ğŸ“š

#### Additional Resources ğŸ“š

dsRAG: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)

Relevant Segment Extraction ğŸ§©:Overview ğŸ”Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.Implementation ğŸ› ï¸Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.

Relevant Segment Extraction ğŸ§©:

Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.

Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.

Context Enrichment Techniques ğŸ“

Context Enrichment Techniques ğŸ“

Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.

Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.

Dividing documents based on semantic coherence rather than fixed sizes.

Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.

Additional Resources ğŸ“š

#### Additional Resources ğŸ“š

Semantic Chunking: Improving AI Information Retrieval- A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.

Contextual Compression ğŸ—œï¸

Compressing retrieved information while preserving query-relevant content.

Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.

Document Augmentation through Question Generation for Enhanced Retrieval

This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.

Use an LLM to augment text dataset with all possible questions that can be asked to each document.

ğŸš€ Advanced Retrieval Methods

### ğŸš€ Advanced Retrieval Methods

Fusion Retrieval ğŸ”—LangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Optimizing search results by combining different retrieval methods.Implementation ğŸ› ï¸Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.

Optimizing search results by combining different retrieval methods.

Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.

Intelligent Reranking ğŸ“ˆLangChain:LlamaIndex:Runnable ScriptOverview ğŸ”Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.Implementation ğŸ› ï¸ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.Additional Resources ğŸ“šRelevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.

Intelligent Reranking ğŸ“ˆ

Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.

ğŸ§ LLM-based Scoring:Use a language model to score the relevance of each retrieved chunk.

ğŸ”€Cross-Encoder Models:Re-encode both the query and retrieved documents jointly for similarity scoring.

ğŸ†Metadata-enhanced Ranking:Incorporate metadata into the scoring process for more nuanced ranking.

Additional Resources ğŸ“š

#### Additional Resources ğŸ“š

Relevance Revolution: How Re-ranking Transforms RAG Systems- A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.

Multi-faceted Filtering ğŸ”Overview ğŸ”Applying various filtering techniques to refine and improve the quality of retrieved results.Implementation ğŸ› ï¸ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.

Multi-faceted Filtering ğŸ”

Applying various filtering techniques to refine and improve the quality of retrieved results.

ğŸ·ï¸Metadata Filtering:Apply filters based on attributes like date, source, author, or document type.

ğŸ“ŠSimilarity Thresholds:Set thresholds for relevance scores to keep only the most pertinent results.

ğŸ“„Content Filtering:Remove results that don't match specific content criteria or essential keywords.

ğŸŒˆDiversity Filtering:Ensure result diversity by filtering out near-duplicate entries.

Hierarchical Indices ğŸ—‚ï¸LangChain:Runnable ScriptOverview ğŸ”Creating a multi-tiered system for efficient information navigation and retrieval.Implementation ğŸ› ï¸Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.Additional Resources ğŸ“šHierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.

Hierarchical Indices ğŸ—‚ï¸

Creating a multi-tiered system for efficient information navigation and retrieval.

Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.

Additional Resources ğŸ“š

#### Additional Resources ğŸ“š

Hierarchical Indices: Enhancing RAG Systems- A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.

Ensemble Retrieval ğŸ­Overview ğŸ”Combining multiple retrieval models or techniques for more robust and accurate results.Implementation ğŸ› ï¸Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.

Combining multiple retrieval models or techniques for more robust and accurate results.

Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.

Dartboard Retrieval ğŸ¯LangChain:Overview ğŸ”Optimizing over Relevant Information Gain in RetrievalImplementation ğŸ› ï¸Combine both relevance and diversity into a single scoring function and directly optimize for it.POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.

Dartboard Retrieval ğŸ¯

Optimizing over Relevant Information Gain in Retrieval

Combine both relevance and diversity into a single scoring function and directly optimize for it.

POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.

Multi-modal Retrieval ğŸ“½ï¸Overview ğŸ”Extending RAG capabilities to handle diverse data types for richer responses.Implementation ğŸ› ï¸Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.

Multi-modal Retrieval ğŸ“½ï¸

Extending RAG capabilities to handle diverse data types for richer responses.

Multi-model RAG with Multimedia Captioning:- Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.

Multi-model RAG with Colpali:- Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.

ğŸ” Iterative and Adaptive Techniques

### ğŸ” Iterative and Adaptive Techniques

Retrieval with Feedback Loops ğŸ”LangChain:Runnable ScriptOverview ğŸ”Implementing mechanisms to learn from user interactions and improve future retrievals.Implementation ğŸ› ï¸Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.

Retrieval with Feedback Loops ğŸ”

Implementing mechanisms to learn from user interactions and improve future retrievals.

Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.

Adaptive Retrieval ğŸ¯LangChain:Runnable ScriptOverview ğŸ”Dynamically adjusting retrieval strategies based on query types and user contexts.Implementation ğŸ› ï¸Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.

Dynamically adjusting retrieval strategies based on query types and user contexts.

Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.

Iterative Retrieval ğŸ”„Overview ğŸ”Performing multiple rounds of retrieval to refine and enhance result quality.Implementation ğŸ› ï¸Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.

Iterative Retrieval ğŸ”„

Performing multiple rounds of retrieval to refine and enhance result quality.

Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.

DeepEval Evaluation:| Comprehensive RAG system evaluation |Overview ğŸ”Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.Implementation ğŸ› ï¸Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.

DeepEval Evaluation:| Comprehensive RAG system evaluation |

Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.

Use thedeepevallibrary to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.

GroUSE Evaluation:| Contextually-grounded LLM evaluation |Overview ğŸ”Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.Implementation ğŸ› ï¸Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.

GroUSE Evaluation:| Contextually-grounded LLM evaluation |

Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.

Use thegrousepackage to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.

ğŸ”¬ Explainability and Transparency

### ğŸ”¬ Explainability and Transparency

Explainable Retrieval ğŸ”LangChain:Runnable ScriptOverview ğŸ”Providing transparency in the retrieval process to enhance user trust and system refinement.Implementation ğŸ› ï¸Explain why certain pieces of information were retrieved and how they relate to the query.

Explainable Retrieval ğŸ”

Providing transparency in the retrieval process to enhance user trust and system refinement.

Explain why certain pieces of information were retrieved and how they relate to the query.

ğŸ—ï¸ Advanced Architectures

### ğŸ—ï¸ Advanced Architectures

Agentic RAG with Contextual AI ğŸ¤–Agentic RAG:Overview ğŸ”Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.Implementation ğŸ› ï¸Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documentsInstruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting informationGrounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use casesLMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performance

Agentic RAG with Contextual AI ğŸ¤–

Building production-ready agentic RAG pipelines for financial document analysis with Contextual AI's managed platform. This comprehensive tutorial demonstrates how to leverage agentic RAG to solve complex queries through intelligent query reformulation, document parsing, reranking, and grounded language models.

Document Parser: Enterprise-grade parsing with vision models for complex tables, charts, and multi-page documents

Instruction-Following Reranker: SOTA reranker with instruction-following capabilities for handling conflicting information

Grounded Language Model (GLM): World's most grounded LLM specifically engineered to minimize hallucinations for RAG use cases

LMUnit: Natural language unit testing framework for evaluating and optimizing RAG system performance

Graph RAG with Milvus Vector Database ğŸ”Graph RAG with Milvus:Overview ğŸ”A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.Implementation ğŸ› ï¸Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collectionsPerform multi-way retrieval by querying both collectionsUse an LLM to rerank retrieved relationships based on their relevance to the queryRetrieve the final passages based on the most relevant relationships

Graph RAG with Milvus Vector Database ğŸ”

Graph RAG with Milvus:

A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.

Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collections

Perform multi-way retrieval by querying both collections

Use an LLM to rerank retrieved relationships based on their relevance to the query

Retrieve the final passages based on the most relevant relationships

Knowledge Graph Integration (Graph RAG) ğŸ•¸ï¸LangChain:Runnable ScriptOverview ğŸ”Incorporating structured data from knowledge graphs to enrich context and improve retrieval.Implementation ğŸ› ï¸Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.

Knowledge Graph Integration (Graph RAG) ğŸ•¸ï¸

Incorporating structured data from knowledge graphs to enrich context and improve retrieval.

Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.

GraphRag (Microsoft) ğŸ¯GraphRag:Overview ğŸ”Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMsImplementation ğŸ› ï¸â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.

GraphRag (Microsoft) ğŸ¯

Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMs

â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.

RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³LangChain:Runnable ScriptOverview ğŸ”Implementing a recursive approach to process and organize retrieved information in a tree structure.Implementation ğŸ› ï¸Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.

RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³

Implementing a recursive approach to process and organize retrieved information in a tree structure.

Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.

Self RAG ğŸ”LangChain:Runnable ScriptOverview ğŸ”A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.Implementation ğŸ› ï¸â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.

A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.

â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.

Corrective RAG ğŸ”§LangChain:Runnable ScriptOverview ğŸ”A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.Implementation ğŸ› ï¸â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.

A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.

â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.

ğŸŒŸ Special Advanced Technique ğŸŒŸ

## ğŸŒŸ Special Advanced Technique ğŸŒŸ

Sophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–Overview ğŸ”An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.Implementation ğŸ› ï¸â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.

Sophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–

An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the "brain" ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.

â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.

To begin implementing these advanced RAG techniques in your projects:

Clone this repository:git clone https://github.com/NirDiamant/RAG_Techniques.git

git clone https://github.com/NirDiamant/RAG_Techniques.git

```
git clone https://github.com/NirDiamant/RAG_Techniques.git
```

```
git clone https://github.com/NirDiamant/RAG_Techniques.git
```

Navigate to the technique you're interested in:cd all_rag_techniques/technique-name

cd all_rag_techniques/technique-name

```
cd all_rag_techniques/technique-name
```

```
cd all_rag_techniques/technique-name
```

Follow the detailed implementation guide in each technique's directory.

We welcome contributions from the community! If you have a new technique or improvement to suggest:

Create your feature branch:git checkout -b feature/AmazingFeature

```
git checkout -b feature/AmazingFeature
```

Commit your changes:git commit -m 'Add some AmazingFeature'

```
git commit -m 'Add some AmazingFeature'
```

Push to the branch:git push origin feature/AmazingFeature

```
git push origin feature/AmazingFeature
```

This project is licensed under a custom non-commercial license - see theLICENSEfile for details.

â­ï¸ If you find this repository helpful, please consider giving it a star!

Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search

AboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repositoryReleasesNo releases publishedSponsor this projectNirDiamantSponsorLearn more about GitHub SponsorsPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.Contributors31+ 17 contributorsLanguagesJupyter Notebook94.9%Python5.1%

AboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repositoryReleasesNo releases publishedSponsor this projectNirDiamantSponsorLearn more about GitHub SponsorsPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.Contributors31+ 17 contributorsLanguagesJupyter Notebook94.9%Python5.1%

AboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repository

AboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repository

AboutThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.Topicspythonaitutorialsragllmllmslangchainllama-indexopeaniResourcesReadmeLicenseView licenseContributingContributingUh oh!There was an error while loading.Please reload this page.ActivityStars22.5kstarsWatchers226watchingForks2.5kforksReport repository

This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.

pythonaitutorialsragllmllmslangchainllama-indexopeani

pythonaitutorialsragllmllmslangchainllama-indexopeani

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

There was an error while loading.Please reload this page.

ReleasesNo releases published

ReleasesNo releases published

No releases published

Sponsor this projectNirDiamantSponsorLearn more about GitHub Sponsors

Sponsor this projectNirDiamantSponsorLearn more about GitHub Sponsors

Learn more about GitHub Sponsors

Packages0No packages published

Packages0No packages published

No packages published

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

Uh oh!There was an error while loading.Please reload this page.

There was an error while loading.Please reload this page.

Contributors31+ 17 contributors

Contributors31+ 17 contributors

LanguagesJupyter Notebook94.9%Python5.1%

LanguagesJupyter Notebook94.9%Python5.1%

Jupyter Notebook94.9%

