input,expected_output,expected_articles
"Unter der Bedingung, dass das Papier von Richard Shin und anderen aus dem Jahr 2021 sich mit den Herausforderungen von LLMs in Regressionstasks beschäftigt, wie lautet der Titel dieses Papiers?",Constrained language models yield few-shot semantic parsers.,general_surveys/3560815.pdf
"Welche Modelle werden als Beispiele für vortrainierte Sprachmodelle in der modernen Ära genannt, insbesondere unter der Bedingung, dass sie effektiv in der Lage sind, den Raum der Argumentation zu erkunden und unversprechende Pfade frühzeitig zu beschneiden?","BERT [Devlin et al., 2019] und GPT [Brown et al., 2020]",general_surveys/2501.09223v2.pdf
"Unter der Bedingung, dass 'Free Dolly' als weltweit erstes wirklich offenes, instruktionsabgestimmtes LLM eingeführt wurde, welche Herausforderungen und Anwendungen von Large Language Models werden im gegebenen Kontext diskutiert?","'Free Dolly' ist die Einführung des weltweit ersten wirklich offenen, instruktionsabgestimmten LLM.",general_surveys/2303.18223v16.pdf
"Unter der Bedingung, dass der Artikel 'Character-llm: A trainable agent for role-playing' im Kontext von Veranstaltungen erwähnt wird, welche Konferenz wird dabei genannt?",EMNLP 2023 in Singapur.,general_surveys/2303.18223v16.pdf
"Welche Normalisierungspositionen werden in LLMs verwendet, insbesondere im Kontext der CoT-Prompting-Ansätze, die eine schrittweise Generierung erfordern?","Es gibt drei allgemeine Optionen für die Normalisierungsposition: post-LN, pre-LN und sandwich-LN.",general_surveys/2303.18223v16.pdf
"Unter der Bedingung, dass der Artikel 'Diffusion models beat gans on image synthesis' in einem der Jahre veröffentlicht wurde, die in den zitierten Arbeiten im Kontext erwähnt werden, in welchem Jahr wurde er dann veröffentlicht?",2021,general_surveys/682263.pdf
Welche Konferenzbeiträge aus dem Jahr 2024 berücksichtigen die Herausforderungen der Halluzinationen und des Wissensstandes bei großen Sprachmodellen und bieten Lösungsansätze dafür?,"[Ge et al., 2024] Yuan Ge et al. und [Gou et al., 2024] Zhibin Gou et al.",general_surveys/2501.09223v2.pdf
"Unter der Voraussetzung, dass der Artikel von A. Sudmann auch die medienpolitische Dimension der Barrierefreiheit in der künstlichen Intelligenz behandelt, in welchem Jahr wurde er veröffentlicht?",2018,general_surveys/682263.pdf
"Unter der Voraussetzung, dass das Papier auf eine umfassende Analyse abzielt, welches Werk untersucht die anhaltende anti-muslimische Voreingenommenheit in großen Sprachmodellen?","A. Abid, M. Farooqi, and J. Zou, “Persistent anti- muslim bias in large language models,” in AIES ’21: AAAI/ACM Conference on AI, Ethics, and Society, Virtual Event, USA, May 19-21, 2021.",general_surveys/2303.18223v16.pdf
"Unter der Voraussetzung, dass das Papier auch auf die Herausforderungen der Barrierefreiheit eingeht, welche drei populären LLM-Familien werden in dem Papier besprochen?","GPT, LLaMA, PaLM",general_surveys/2402.06196v3.pdf
"Welcher Artikel behandelt das Thema 'Rationale-augmented ensembles in language models', vorausgesetzt, dass die Modelle speziell für fortgeschrittene Fähigkeiten wie die Unterstützung externer Plugins optimiert wurden?","Der Artikel von X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi und D. Zhou mit dem Titel 'Rationale-augmented ensembles in language models' wird im Jahr 2022 in CoRR veröffentlicht.",general_surveys/2303.18223v16.pdf
"Unter der Bedingung, dass der Artikel 'Large language models are better reasoners with self-verification' sich mit komplexem Problemlösen durch fortgeschrittene Methoden wie least-to-most prompting beschäftigt, welche Autoren haben zu diesem Artikel beigetragen?","Y. Weng, M. Zhu, F. Xia, B. Li, S. He, K. Liu, und J. Zhao",general_surveys/2303.18223v16.pdf
"Unter der Bedingung, dass Meta alle seine entwickelten LLMs als Open-Source bereitstellt, welche spezifischen Beiträge leistet das Unternehmen zur Förderung der Forschung und Entwicklung von Open-Source-LLMs?","Meta trägt erheblich zu Open-Source-LLMs bei und fördert die Forschung an LLMs. Meta zeichnet sich als eines der großzügigsten kommerziellen Unternehmen aus, da alle von Meta entwickelten LLMs Open-Source sind.",general_surveys/2304.13712v2.pdf
"Unter der Bedingung, dass der Artikel von S. Wu, H. Fei, L. Qu, W. Ji und T.-S. Chua im Jahr 2023 veröffentlicht wurde, was ist das zentrale Thema dieser Veröffentlichung?",Next-gpt: Any-to-any multimodal llm,general_surveys/2402.06196v3.pdf
"Welche spezifischen Bereiche werden in der Umfrage zu Anwendungen von LLMs behandelt, unter der Bedingung, dass die Umfrage auch auf die Herausforderungen bei der Implementierung in verschiedenen Sektoren eingeht?","Die Umfrage behandelt Anwendungen von LLMs in verschiedenen Bereichen, darunter Medizin, Bildung, Finanzen, Ingenieurwesen, Medien, Unterhaltung, Politik und Recht.",general_surveys/682263.pdf
"Unter der Bedingung, dass 15% der Tokens in einem BERT-ähnlichen Maskierungsprozess zufällig ausgewählt werden, was ist das Ziel der effizienten Feinabstimmung bei großen Sprachmodellen (LLMs)?","Mit dem Aufkommen von LLMs hat die effiziente Feinabstimmung zunehmende Forschungsaufmerksamkeit erlangt, um einen leichteren Anpassungsansatz für nachgelagerte Aufgaben zu entwickeln.",general_surveys/2303.18223v16.pdf
"Welche Veröffentlichung behandelt die Nutzung von ChatGPT im juristischen Bildungsbereich unter der Bedingung, dass die Veröffentlichung auch auf die Feinabstimmung von Modellen eingeht?","J. H. Choi, K. E. Hickman, A. Monahan, und D. B. Schwarcz, „ChatGPT Goes to Law School,“ Journal of Legal Education, Januar 2023. Forthcoming.",general_surveys/682263.pdf
"Unter welchen Bedingungen können große Sprachmodelle (LLMs) bei bestimmten Aufgaben nicht überlegen sein, insbesondere wenn die Aufgaben spezielles Wissen erfordern, das nicht durch die reale Welt abgedeckt wird?","In einigen Aufgaben ist das erforderliche Wissen nicht das von LLMs über die reale Welt gelernte Wissen. In solchen Fällen können LLMs nicht gut arbeiten, da das Wissen innerhalb der LLMs über die reale Welt für die Aufgabe nutzlos ist oder das erforderliche Wissen sogar im Widerspruch zur realen Welt steht.",general_surveys/2304.13712v2.pdf
"Unter der Voraussetzung, dass das Papier von B. Guo und anderen im Jahr 2023 in einem renommierten Journal veröffentlicht wurde, wie lautet der vollständige Titel dieses Papiers?","How close is chatgpt to human experts? comparison corpus, evaluation, and detection.",general_surveys/2303.18223v16.pdf
"Wie beeinflusst die Instruktionsausrichtung bei großen Sprachmodellen (LLMs) deren Fähigkeit, auf Benutzeranweisungen zu reagieren, insbesondere im Kontext der in der Literatur erwähnten Modelle wie BERT oder RoBERTa?","Das Ziel der Instruktionsausrichtung (oder Instruktions-Feinabstimmung) ist es, das LLM so zu tunen, dass es genau auf Benutzeranweisungen und -absichten reagiert.",general_surveys/2501.09223v2.pdf
