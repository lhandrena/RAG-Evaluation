input,expected_output,expected_articles
Wie viele Parameter hat das Modell GPT-2 und was ist ein Hauptmerkmal von GPT-3 im Vergleich zu GPT-2?,"Das Modell GPT-2 hat insgesamt 1,5 Milliarden Parameter, während GPT-3 eine Modellgröße von 175 Milliarden Parametern hat und kein Fine-Tuning für spezifische nachgelagerte Aufgaben benötigt.",general_surveys/2302.09419v3.pdf
Was beschreibt das Papier 'Gptq' und worum geht es in dem Blogbeitrag von A. Frömmgen und L. Kharatyan?,"Das Papier 'Gptq' beschreibt eine genaue Nachtraining-Quantisierung für generative Pre-Trained Transformer, während der Blogbeitrag von A. Frömmgen und L. Kharatyan das Lösen von Code-Review-Kommentaren mit maschinellem Lernen behandelt.",general_surveys/2307.10169v1.pdf
"Welche Autoren haben an dem Artikel 'Chatgpt goes to law school' mitgewirkt und welche Publikation behandelt die Frage, ob GPT-3 gesetzliche Argumentation durchführen kann?","Die Autoren des Artikels 'Chatgpt goes to law school' sind J. H. Choi, K. E. Hickman, A. Monahan und D. Schwarcz, und die Publikation, die die Frage behandelt, ob GPT-3 gesetzliche Argumentation durchführen kann, ist von A. Blair-Stanek, N. Holzenberger und B. V. Durme, veröffentlicht in CoRR, vol. abs/2302.06100, 2023.",general_surveys/2303.18223v16.pdf
Wie können LLMs zur Auswahl von Demonstrationen verwendet werden und wie wird die Demonstrationsauswahl als RL-Problem formuliert?,"LLMs können genutzt werden, um die Informationsgehalt jedes Beispiels direkt zu messen, basierend auf dem Leistungsgewinn nach Hinzufügen des Beispiels, und die Aufgabe der Demonstrationsauswahl kann in ein RL-Problem formuliert werden, wobei LLMs als Belohnungsfunktion dienen, um Feedback für das Training des Politikmodells bereitzustellen.",general_surveys/2303.18223v16.pdf
Was sind die Ziele von Instruction-Aligning-Methoden bei großen Sprachmodellen und wie wird das Supervised Fine-Tuning (SFT) durchgeführt?,"Instruction-aligning methods zielen darauf ab, das Sprachmodell dazu zu bringen, menschlichen Absichten zu folgen und sinnvolle Ausgaben zu erzeugen, während das Supervised Fine-Tuning (SFT) eine Technik ist, bei der das vortrainierte Sprachmodell mit einem hochwertigen Korpus auf eine überwachte Weise feinabgestimmt wird, um Wissen zu erschließen und auf spezifische, reale Aufgaben anzuwenden.",general_surveys/2302.09419v3.pdf
Wer sind einige der Herausgeber der Konferenzberichte über maschinelle Übersetzung im Jahr 2020 und in welchem Jahr fand die sechste Konferenz über maschinelle Übersetzung (WMT21) statt?,"Einige der Herausgeber der Konferenzberichte über maschinelle Übersetzung im Jahr 2020 sind L. Barrault, O. Bojar, F. Bougares, R. Chatterjee, M. R. Costa-jussà und C. Federmann, und die sechste Konferenz über maschinelle Übersetzung (WMT21) fand im Jahr 2021 statt.",general_surveys/2303.18223v16.pdf
Welche Autoren haben an dem Artikel 'Fast random walk graph kernel' mitgewirkt und in welchem Jahr wurde der Artikel 'Weisfeiler-lehman graph kernels' veröffentlicht?,"Die Autoren des Artikels 'Fast random walk graph kernel' sind U. Kang, H. Tong und J. Sun, und der Artikel 'Weisfeiler-lehman graph kernels' wurde im Jahr 2011 veröffentlicht.",general_surveys/2302.09419v3.pdf
Welche Themen werden in der Arbeit von M. Fraiwan und N. Khasawneh behandelt und in welchem Jahr wurde der Artikel 'The virtue of simplicity: On machine learning models in algorithmic trading' von K. B. Hansen veröffentlicht?,"Die Arbeit von M. Fraiwan und N. Khasawneh behandelt Anwendungen von ChatGPT in den Bereichen Bildung, Marketing, Softwaretechnik und Gesundheitswesen sowie deren Vorteile, Nachteile und Forschungsrichtungen, und der Artikel von K. B. Hansen wurde im Jahr 2020 veröffentlicht.",general_surveys/682263.pdf
"Was ist das Chinchilla-Modell und wie unterscheidet es sich vom Gopher-Modell, und wie verbessert das AlexaTM-Modell das In-Context-Lernen?","Das Chinchilla-Modell ist ein kausaler Decoder, der auf demselben Datensatz wie das Gopher-Modell trainiert wurde, jedoch mit einer leicht unterschiedlichen Datenverteilungsstrategie und dem AdamW-Optimizer anstelle von Adam, und zeigt, dass die Modellgröße für jede Verdopplung der Trainings-Token verdoppelt werden sollte. Das AlexaTM-Modell verbessert das In-Context-Lernen, indem es während des Trainings den CLM-Aufgabe für 20% der Zeit anwendet.",general_surveys/2307.06435v8.pdf
"Was wird verwendet, um ein binäres Klassifikationssystem zu erstellen und welche Art von Modellierung wird in der Masked Language Modeling Aufgabe verwendet?","Ein Softmax-Layer wird auf h0 hinzugefügt, um ein binäres Klassifikationssystem zu erstellen, und in der Masked Language Modeling Aufgabe wird eine Reihenfolge von x0,[MASK],x2,[MASK],x4 verwendet, um x1 und x3 vorherzusagen.",general_surveys/2501.09223v2.pdf
Was ist der Titel des Papiers von M. Besta und Kollegen im Jahr 2023 und welches Papier befasst sich mit der Förderung des logischen Denkens in großen Sprachmodellen?,"Der Titel des Papiers von M. Besta und Kollegen im Jahr 2023 ist 'Graph of thoughts: Solving elaborate problems with large language models', und das Papier 'Boosting logical reasoning in large language models through a new framework: The graph of thought' von B. Lei, P. Lin, C. Liao und C. Ding befasst sich mit der Förderung des logischen Denkens in großen Sprachmodellen.",general_surveys/2303.18223v16.pdf
Wer sind die Autoren des Artikels 'Rome was built in 1776: A case study on factual correctness in knowledge-grounded response generation' und in welchem Jahr wurde der Artikel 'Machine learning: The high interest credit card of technical debt' veröffentlicht?,"Die Autoren des Artikels 'Rome was built in 1776: A case study on factual correctness in knowledge-grounded response generation' sind S. Santhanam, B. Hedayatnia, S. Gella, A. Padmakumar, S. Kim, Y. Liu und D. Z. Hakkani-T¨ur, und der Artikel 'Machine learning: The high interest credit card of technical debt' wurde im Jahr 2014 veröffentlicht.",general_surveys/2402.06196v3.pdf
Welche vier gängigen Aufgaben zur Graph-Augmentation werden im GraphCL-Modell eingeführt und wie maximiert DGI die gegenseitige Information in Graphen?,"Im GraphCL-Modell werden vier gängige Aufgaben zur Graph-Augmentation eingeführt: Knotenentfernung, Kantenstörung, Attributmaskierung und Teilgraph-Sampling; DGI maximiert die gegenseitige Information, indem es die MI zwischen der Patch-Darstellung und der Zusammenfassung der entsprechenden hochrangigen Graphen maximiert, die alle mit der etablierten Graph-Convolutional-Network-Architektur abgeleitet werden.",general_surveys/2302.09419v3.pdf
Was ist das Winograd Schema Challenge (WSC) und wofür wird das RACE-High-Dataset verwendet?,"Das Winograd Schema Challenge (WSC) ist eine Leseverständnisaufgabe, bei der ein System Referenzen in einem Text auflösen muss, was oft Weltwissen und Schlussfolgerungen über den Text erfordert, während das RACE-High-Dataset verwendet wird, um die Verständnisfähigkeit von Modellen in einem akademischen und herausfordernden Kontext zu bewerten, da es aus englischen Prüfungsfragen auf High-School-Niveau besteht.",general_surveys/2307.06435v8.pdf
"Welche Experimente werden in dem Dokument 'Sparks of artificial general intelligence: Early experiments with gpt-4' erwähnt und wer sind die Autoren des Papiers 'The malicious use of artificial intelligence: Forecasting, prevention, and mitigation'?","Das Dokument erwähnt frühe Experimente mit gpt-4 im Zusammenhang mit künstlicher allgemeiner Intelligenz und die Autoren des Papiers sind M. Brundage, S. Avin, J. Clark, H. Toner, P. Eckersley, B. Garfinkel, A. Dafoe, P. Scharre et al.",general_surveys/2307.10169v1.pdf
Was ist das Thema des Papiers von T. Carta und Kollegen im Jahr 2023 und welches Papier behandelt allgemein fähige Agenten für offene Umgebungen in Minecraft?,"Das Papier von T. Carta und Kollegen im Jahr 2023 behandelt die Verankerung großer Sprachmodelle in interaktiven Umgebungen mit Online-Verstärkungslernen, während das Papier von X. Zhu und Kollegen mit dem Titel 'Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory' allgemein fähige Agenten für offene Umgebungen in Minecraft behandelt.",general_surveys/2303.18223v16.pdf
"Was ist das Thema des Datensatzes, der von D. Jin und anderen in der Zeitschrift Applied Sciences veröffentlicht wurde, und was ist das Ziel des Projekts 'Stanford alpaca' von R. Taori und anderen?","Der Datensatz befasst sich mit der Frage 'Welche Krankheit hat dieser Patient?' und ist ein groß angelegter offener Frage-Antwort-Datensatz aus medizinischen Prüfungen, während das Ziel des Projekts 'Stanford alpaca' ist es, ein Anweisungen befolgendes Llama-Modell zu entwickeln.",general_surveys/2303.18223v16.pdf
Wie verwenden Gao et al. das vortrainierte Sprachmodell T5 im Template-Suchprozess und was untersuchen Davison et al. im Zusammenhang mit der Vervollständigung von Wissensbasen?,"Gao et al. verwenden T5, um Template-Token zu generieren, indem sie die Position zum Einfügen von Template-Token innerhalb eines Templates angeben und Trainingsbeispiele bereitstellen, damit T5 die Template-Token dekodieren kann, während Davison et al. die Aufgabe der Wissensbasis-Vervollständigung untersuchen und ein Template für ein Eingabe-Triple (head-relation-tail) unter Verwendung von Sprachmodellen entwerfen.",general_surveys/3560815.pdf
"Was ist der Titel des Papiers, das von S. Smith und anderen im Jahr 2022 veröffentlicht wurde, und welches Modell wird im Papier von W. Ben und K. Aran im Jahr 2021 beschrieben?","Das Papier von S. Smith und anderen im Jahr 2022 trägt den Titel 'Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model', und das Modell, das im Papier von W. Ben und K. Aran im Jahr 2021 beschrieben wird, ist 'Gpt-j-6b: A 6 billion parameter autoregressive language model'.",general_surveys/2307.06435v8.pdf
Welche Herausforderungen haben große Sprachmodelle (LLMs) bei der Lösung von Sequence Tagging Aufgaben und warum schneiden sie bei der Informationsextraktion oft schlechter ab als Methoden mit vollständigem Daten-Finetuning?,"LLMs haben Schwierigkeiten, spezielle Kategorien mit mehrdeutigen oder seltenen Namen zu lösen, wie z.B. die 'MISC' und 'ORG' Klassen, da sie möglicherweise die Bedeutungen dieser Klassen im menschlich annotierten Datensatz missverstehen, und bei der Informationsextraktion müssen komplexe semantische Beziehungen genau verstanden und verarbeitet werden, wobei in-context learning mit LLMs typischerweise schlechter abschneidet als state-of-the-art Methoden mit vollständigem Daten-Finetuning.",general_surveys/2303.18223v16.pdf
