input,expected_output,expected_articles
Unter welchen Bedingungen und mit welchen spezifischen Anpassungen zeigt Abbildung 3.5 die Feinabstimmung von Präfixen für die Übersetzungsaufgabe?,"Abbildung 3.5 zeigt eine Illustration des Prefix-Fine-Tunings für eine Übersetzungsaufgabe, bei der nur die Präfixvektoren pl 1 durch das Empfangen der Fehlgradienten vom Ausgang (d.h. der chinesischen Übersetzung) aktualisiert werden.",general_surveys/2501.09223v2.pdf
"Inwiefern beeinflusst die Vielfalt der Pretraining-Daten die Leistung von LLMs, insbesondere in Bezug auf die Fähigkeit, kontextbezogene und kohärente Antworten zu generieren, und welche Beispiele gibt es für Modelle, die von dieser Vielfalt profitieren?","Die Vielfalt der Pretraining-Daten spielt eine entscheidende Rolle bei der Gestaltung der Leistung des Modells, da sie das Modell mit einem reichen Verständnis von Wortwissen, Grammatik, Syntax und Semantik informiert und die Fähigkeit zur Kontexterkennung und zur Generierung kohärenter Antworten verbessert.",general_surveys/2304.13712v2.pdf
"Was ist die Bedeutung und mögliche Konsequenz, wenn der Wert von πθ(at|st) im Vergleich zu πθref(at|st) größer als 1 ist, unter der Bedingung, dass die aktuelle Politik die vorherige übertrifft?","Wenn πθ(at|st) (at|st) > 1 ist, wird die Aktion at von der aktuellen Politik im Vergleich zur Referenzpolitik mehr bevorzugt.",general_surveys/2501.09223v2.pdf
"Welche spezifische Herausforderung wird im Artikel von P. Clark et al. bezüglich des AI2 Reasoning Challenge beschrieben und welche Bedingungen müssen erfüllt sein, um diese zu bewältigen?","Das AI2 Reasoning Challenge stellt die Herausforderung dar, ob man das Frage-Antworten wirklich gelöst hat.",general_surveys/2402.06196v3.pdf
"Welche spezifischen Techniken wurden in den letzten Jahren entwickelt, um die Effektivität des Promptings bei großen Sprachmodellen zu verbessern, und welche dieser Techniken erfordern keine Anpassung der Modellarchitektur?","Techniken wie Few-Shot Learning, Zero-Shot Learning und CoT Reasoning wurden erforscht, um die Effektivität des Promptings zu verbessern.",general_surveys/2501.09223v2.pdf
"Welche Rolle spielt das Long Convolution Modul in Hyena, insbesondere im Vergleich zu einem Attention-Modul, und welche Einschränkungen bringt es mit sich?","Im Long Convolution Modul werden Filter basierend auf relativen Positionen verwendet, um Informationen an verschiedenen Positionen in die mittleren Repräsentationen zu aggregieren, und Gating-Funktionen werden eingesetzt, um die Zwischenrepräsentationen weiter in die endgültige Ausgabe zu projizieren.",general_surveys/2303.18223v16.pdf
"Welche Rolle spielt die Skalierung der Ausgabelänge in großen Sprachmodellen, insbesondere bei Aufgaben, die komplexes Denken erfordern, und wie wird dies in der Praxis umgesetzt?","Die Skalierung der Ausgabelänge bezieht sich auf die Erhöhung der Anzahl der während der Inferenz generierten Tokens. Dies ist besonders wichtig bei Aufgaben, die eine Langform-Generierung erfordern, wie z.B. das Schreiben von Geschichten.",general_surveys/2501.09223v2.pdf
"Unter welchen Bedingungen wird vorgeschlagen, die Instabilität bei der Generierung von CoT durch LLMs mit einer bestimmten Methode zu verbessern, und welche Methode wird bevorzugt?","Sampling-basierte Methoden schlagen vor, mehrere Begründungspfade zu sampeln, anstatt greedy decoding zu verwenden, und Self-Consistency generiert mehrere Begründungspfade und wählt die konsistenteste Antwort durch Mehrheitsabstimmung aus.",general_surveys/2303.18223v16.pdf
"Welche spezifische Modellarchitektur, die auf BERT basiert, wird für die benannte Entitätenerkennung (NER) verwendet, und welche Besonderheiten weist sie im Vergleich zu anderen Klassifikationssystemen auf?","Die Architektur ist die gleiche wie bei BERT-basierten Klassifikationssystemen, mit nur der Änderung der Ausgabeschicht.",general_surveys/2501.09223v2.pdf
"Unter welchen Bedingungen wird die Generierung von Anweisungen und Feinabstimmungsproben durch große Sprachmodelle (LLMs) bevorzugt, insbesondere im Hinblick auf die Kosten und die Vielfalt der generierten Daten?","Die Generierung von Anweisungen und Feinabstimmungsproben durch LLMs wird bevorzugt, da die manuelle Entwicklung solcher Daten so teuer ist, dass sich die meisten Forschungsgruppen dies nicht leisten können.",general_surveys/2501.09223v2.pdf
Unter welcher Bedingung wird im Jahr 2023 von A. K. Lampinen und Kollegen das Thema der passiven Lernstrategien in Agenten und Sprachmodellen behandelt?,Passive learning of active causal strategies in agents and language models.,general_surveys/2307.10169v1.pdf
"Welche praktischen Anwendungen von großen Sprachmodellen (LLMs) werden im Artikel in den Bereichen Medizin, Bildung, Finanzen, Recht, Politik, Medien, Unterhaltung oder Ingenieurwesen unter Berücksichtigung von ethischen Bedenken und technischen Herausforderungen demonstriert?","Der Artikel demonstriert die Anwendungen von LLMs durch vier praktische Anwendungsfälle in den Bereichen Medizin, Bildung, Finanzen, Recht, Politik, Medien, Unterhaltung, Ingenieurwesen und anderen.",general_surveys/682263.pdf
"Welche Personen oder Teams waren an der Entwicklung von mT5 beteiligt, und gibt es spezifische Rollen oder Beiträge, die sie geleistet haben?","L. Xue, N. Constant, A. Roberts, M. Kale, R. Al-Rfou, A. Siddhant, A. Barua und C. Raffel.",general_surveys/2307.10169v1.pdf
"Welche Methoden gibt es, um LLMs zur Erstellung von Eingabeaufforderungen zu verwenden, und welche Rolle spielt dabei die Bereitstellung von Eingabe-Ausgabe-Paaren?","LLMs können zur Erstellung von Eingabeaufforderungen verwendet werden, indem ihnen eine Beschreibung der Aufgabe gegeben wird oder indem sie Beispiele für die Eingabe und Ausgabe der Aufgabe erhalten. Sie können dann die entsprechende Anweisung für die Aufgabe aus den bereitgestellten Eingaben und Ausgaben ableiten.",general_surveys/2501.09223v2.pdf
"Welche spezifischen Aufgaben kann der Code Interpreter Plugin von OpenAI ausführen, und welche Bedingungen müssen erfüllt sein, damit er Python-Code basierend auf einer menschlichen Sprachbeschreibung generieren kann?","Der Code Interpreter ist ein integrierter Python-Code-Interpreter, der für logische Berechnungen sowie zum Schreiben von Code verwendet werden kann.",general_surveys/682263.pdf
"Welche spezifische Technik könnte verwendet werden, um die ursprüngliche Abfrage zu optimieren und sicherzustellen, dass mehr relevante Dokumente abgerufen werden, insbesondere wenn die ursprüngliche Abfrage mehrdeutig ist?","Die Technik der Abfrageumschreibung (query rewriting) kann verwendet werden, um den Inhalt der Abfrage zu ändern, um wichtige Informationen hervorzuheben und potenzielle Unklarheiten zu beseitigen, was das Abrufen verwandter Dokumente erleichtert.",general_surveys/2303.18223v16.pdf
"Welche spezifische Metrik wird verwendet, um die Zeitspanne zu messen, die vom Beginn einer Anfrage bis zur Generierung des ersten Tokens einer Antwort vergeht, unter der Bedingung, dass die Datenübertragung nicht viel Zeit in Anspruch nimmt?",Time to First Token (TTFT).,general_surveys/2501.09223v2.pdf
"Gemäß der Gleichung (5.1) im Dokument, welches Ziel verfolgt die LLM-Inferenz, wenn man die Bedingung Pr(y|x) maximieren möchte, und welche Methode wird dabei bevorzugt, um das Problem zu lösen, ohne auf Sequenz-zu-Sequenz-Modelle zurückzugreifen?","Das Ziel der LLM-Inferenz ist es, Pr(y|x) zu maximieren.",general_surveys/2501.09223v2.pdf
"Welche Vorteile bietet die Nutzung eines Key-Value-Datenspeichers bei der effizienten Wiederverwendung von Präfixen, insbesondere im Hinblick auf die Verwaltung von Speicherplatz und die Vermeidung der Neuberechnung versteckter Zustände?","Die Verwendung eines Key-Value-Datenspeichers ermöglicht es, häufig vorkommende Präfixe ihren vorkomputierten KV-Caches zuzuordnen, was einen konstantzeitlichen Zugriff auf die zwischengespeicherten Zustände erlaubt.",general_surveys/2501.09223v2.pdf
"Welche Modelle, die als Decoder fungieren, sind in der Liste der großen Sprachmodelle enthalten, und welche spezifischen Eigenschaften oder Verwendungszwecke zeichnen sie aus?","PaLM, LaMDA, OPT, InstructGPT, Sparrow, BLOOM, ExT5",general_surveys/2303.04226v1.pdf
