input,expected_output,expected_articles
"Hallo, ich bin eine neugierige Studentin und lese gerade ein komplexes Übersichtsartikel über große Sprachmodelle. Kannst du mir erklären, was der Zweck der Kettenüberlegung beim Prompting ist?","Die Kettenüberlegung kann eingesetzt werden, um das Lernen im Kontext zu verbessern, indem eine Reihe von Zwischenschritten des Denkens in die Prompts einbezogen werden.",general_surveys/2303.18223v16.pdf
"Hallo, ich bereite gerade eine Zusammenfassung für eine Konferenz vor und suche nach Informationen über aktuelle Umfragen zu Halluzinationen in großen Sprachmodellen. Könnten Sie mir sagen, was das Thema der Umfrage von L. Huang und Kollegen in CoRR ist?","Eine Umfrage über Halluzinationen in großen Sprachmodellen: Prinzipien, Taxonomie, Herausforderungen und offene Fragen.",general_surveys/2303.18223v16.pdf
"Hallo, ich bereite gerade eine Präsentation über die Sicherheitslücken von großen Sprachmodellen vor. Könnten Sie mir sagen, welche Methode die sememe-basierte Wortersetzungsmethode mit einem Suchalgorithmus zur Generierung von adversarialen Beispielen kombiniert?","[264] kombiniert die sememe-basierte Wortersetzungsmethode und einen Suchalgorithmus basierend auf der Partikelschwarmoptimierung, um adversariale Beispiele zu generieren.",general_surveys/2302.09419v3.pdf
"Hallo, ich bin gerade mitten in einer intensiven Forschungssitzung und frage mich, welches Papier sich mit der Verbesserung der NLG-Bewertung durch LLM-Paraphrasierung befasst?","T. Tang, H. Lu, Y. E. Jiang, H. Huang, D. Zhang, W. X. Zhao, und F. Wei, „Not all metrics are guilty: Improving NLG evaluation with LLM paraphrasing,“ CoRR, vol. abs/2305.15067, 2023.",general_surveys/2303.18223v16.pdf
"Hallo, ich bin ein neugieriger KI-Forscher und beschäftige mich gerade mit der Kodierungsmethodik von Wissensgraphen. Könnten Sie mir bitte erklären, wie Song et al. das Problem des Informationsverlusts in großen Graphen adressieren?","Song et al. kodieren Graphensemantik mit einem graph-state LSTM, das Informationsweitergabe zwischen Knoten während einer Reihe von Zustandsübergängen ermöglicht.",general_surveys/2303.04226v1.pdf
"Hallo zusammen, ich bereite gerade eine Präsentation über den Einfluss von Instruction Tuning Techniken auf verschiedene Sprachmodelle vor. Kann mir jemand sagen, was eine wichtige Ressource zur Erstellung von Aufgabenbeschreibungen für verschiedene Datensätze ist?",Eine wichtige Ressource zur Erstellung von Aufgabenbeschreibungen für verschiedene Datensätze ist die Crowd-Sourcing-Plattform PromptSource.,general_surveys/2303.18223v16.pdf
"Hallo, ich habe gerade einen Überblick über große Sprachmodelle gelesen und frage mich, wofür die Graphklassifikation (GC) häufig in sozialen und molekularen Daten verwendet wird?","Die Graphklassifikation (GC) wird häufig in sozialen, molekularen und Protein-Grafikdaten verwendet, um die Eigenschaft der gegebenen Gemeinschaft, chemischen Verbindung und des Proteins vorherzusagen.",general_surveys/2302.09419v3.pdf
"Hallo, ich bin Datenanalyst in einem Tech-Unternehmen und untersuche, wie sich große Sprachmodelle an unterschiedliche Datenverteilungen anpassen können. Welche Methode hat speziell die Generalisierungsfähigkeit von LLMs verbessert?",Die Methode des Reinforcement Learning from Human Feedback (RLHF) hat die Generalisierungsfähigkeit von LLMs verbessert.,general_surveys/2304.13712v2.pdf
"Hallo, ich bereite gerade eine Seminarpräsentation über fortgeschrittene Transformer-Architekturen vor. Könnten Sie mir bitte erklären, wie der Reward r im Kontext eines gegebenen Eingangs x und Ausgangs y ausgedrückt wird?","r = Reward(x,y), wobei Reward(·) das Belohnungsmodell ist.",general_surveys/2501.09223v2.pdf
"Hallo, ich interessiere mich sehr für die Herausforderungen bei der Aktualisierung von großen Sprachmodellen. Könnten Sie mir erklären, welche speziellen Schwierigkeiten beim Aktualisieren von isoliertem Modellverhalten oder Faktenwissen auftreten?","Das Aktualisieren von isoliertem Modellverhalten oder Faktenwissen kann teuer und ungezielt sein, was unbeabsichtigte Nebeneffekte verursachen könnte.",general_surveys/2307.10169v1.pdf
"Hallo, auf der Tech-Konferenz habe ich gehört, dass große Sprachmodelle wie GPT-3.5 bei quantitativen Aufgaben in regulatorischen Prüfungen Schwierigkeiten haben. Können Sie mir sagen, wie GPT-3.5 in solchen Szenarien abschneidet?","Das beste Modell (neuestes GPT-3.5) hat Schwierigkeiten mit quantitativer Argumentation und erzielt Ergebnisse, die ähnlich wie zufälliges Raten bei Multiple-Choice-Fragen sind.",general_surveys/2307.10169v1.pdf
"Hallo, ich arbeite an meiner Abschlussarbeit über fortgeschrittene Fähigkeiten von Sprachmodellen. Könnten Sie mir sagen, welche drei grundlegenden Fähigkeiten bei der Evaluierung von LLMs betrachtet werden?","Die drei grundlegenden Fähigkeiten sind Sprachgenerierung, Wissensnutzung und komplexes Denken.",general_surveys/2303.18223v16.pdf
"Hallo, ich bin ein neugieriger Postgraduiertenstudent und lese gerade ein Übersichtsartikel über große Sprachmodelle. Können Sie mir erklären, wie die Forscher die Berechnungskosten senken, wenn sie ein Dokument in mehrere Segmente unterteilen, um die Risiken von KI zu verstehen?","Die Berechnungskosten können gesenkt werden, indem das Dokument in relativ kurze Segmente unterteilt wird und die gleiche Aufgabe auf jedem Segment ausgeführt wird. Diese Segmente können parallel verarbeitet werden, um die Berechnungskosten weiter zu reduzieren.",general_surveys/2501.09223v2.pdf
"Hallo, ich bereite gerade eine Präsentation über Datensets zur Bewertung der Robustheit von Modellen für maschinelles Leseverständnis vor. Könnten Sie mir erklären, was Dureaderrobust ist?",Dureaderrobust ist ein chinesisches Datenset zur Bewertung der Robustheit von Modellen für maschinelles Leseverständnis.,general_surveys/2307.06435v8.pdf
"Hallo, ich bereite gerade ein Seminar über die Implementierung von strukturierten Sprachverarbeitungs-Frameworks in großen Sprachmodellen vor. Könnten Sie mir erklären, was 'Rails' in der fortgeschrittenen Prompt-Entwicklung für LLMs sind?","Rails in der fortgeschrittenen Prompt-Entwicklung beziehen sich auf eine Methode, um die Ausgabe von Large Language Models (LLMs) durch vordefinierte Regeln oder Vorlagen zu steuern und zu kontrollieren. Diese Methode soll sicherstellen, dass die Antworten des Modells bestimmten Standards oder Kriterien entsprechen, um die Relevanz, Sicherheit und Genauigkeit der Ausgabe zu verbessern.",general_surveys/2402.06196v3.pdf
"Hallo, ich bin ein Informatikstudent und interessiere mich für Innovationen im Deep Learning. Könnten Sie mir bitte sagen, was das Hauptthema des Papiers 'Tesseract' von B. Wang, Q. Xu, Z. Bian und Y. You ist?",Das Hauptthema des Papiers 'Tesseract' ist die effiziente Parallelisierung der Tensor-Parallelität.,general_surveys/2303.18223v16.pdf
"Hallo, ich bin ein Forscher und interessiere mich dafür, wie sich verschiedene Bewertungseinstellungen auf die Leistung großer Sprachmodelle auswirken. Könnten Sie mir erklären, welche Vorteile die menschliche Bewertung bei der Beurteilung der Fähigkeiten von LLMs bietet?","Ein Vorteil der menschlichen Bewertung ist ihre Fähigkeit, die tatsächlichen Fähigkeiten von LLMs direkt widerzuspiegeln. Sie bietet eine direktere Messung der Leistung von LLMs in realen Szenarien und ermöglicht eine tiefere Einsicht in die Stärken und Schwächen von LLMs in verschiedenen Aufgaben und Kontexten.",general_surveys/2303.18223v16.pdf
"Hallo, ich bin ein KI-Student und habe die ganze Woche über Forschungsarbeiten gelesen. Können Sie mir erklären, wie die Paraphrasierung in der Prompt-Generierung von Haviv et al. [43] durchgeführt wird? Ich denke darüber nach, wie ich diese Technik für meine Abschlussarbeit über natürliche Sprachverarbeitung nutzen kann.","Haviv et al. [43] führen die Paraphrasierung durch, nachdem die Eingabe x in die Prompt-Vorlage eingefügt wurde, sodass für jede einzelne Eingabe eine andere Paraphrase generiert werden kann.",general_surveys/3560815.pdf
"Hallo, ich bereite gerade eine Präsentation über die Transparenz von Open-Source-Large-Language-Models für eine akademische Konferenz vor. Könnten Sie mir sagen, was das Ziel von LLM360 laut dem Artikel von Z. Liu und anderen ist?","Das Ziel von LLM360 ist es, vollständig transparente Open-Source-LLMs zu entwickeln.",general_surveys/682263.pdf
"Hallo, ich bereite eine Präsentation über die Entwicklung von großen Sprachmodellen vor und möchte wissen, wer die Autoren des Papiers 'Exploring the limits of transfer learning with a unified text-to-text transformer' sind?",Die Autoren werden im gegebenen Kontext nicht genannt.,general_surveys/2501.09223v2.pdf
