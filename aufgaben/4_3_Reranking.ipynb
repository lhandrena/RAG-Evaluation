{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking - Verbesserte Retrieval-Qualität durch Neuordnung\n",
    "\n",
    "## Was ist Reranking?\n",
    "\n",
    "Reranking ist eine **zweistufige Retrieval-Strategie** in RAG-Systemen:\n",
    "\n",
    "1. **Erste Stufe (Initial Retrieval)**: Schnelle Vorauswahl vieler Dokumente mit einfachen Similarity-Scores (z.B. Cosine-Similarity zwischen Embeddings)\n",
    "2. **Zweite Stufe (Reranking)**: Präzise Neuordnung dieser Kandidaten mit einem spezialisierten Modell\n",
    "\n",
    "### Warum ist Reranking wichtig?\n",
    "\n",
    "**Problem mit reinem Vector Search:**\n",
    "- Vector Search verwendet **unabhängige Embeddings** für Query und Dokumente\n",
    "- Die Ähnlichkeit wird durch einen einfachen **Cosine-Score** gemessen\n",
    "- Dies erfasst oft **nicht die semantische Relevanz** zwischen Query und Dokument\n",
    "\n",
    "**Beispiel:**\n",
    "- Query: \"Wie funktioniert maschinelles Lernen?\"\n",
    "- Dokument A: \"Maschinelles Lernen ist ein wichtiges Thema\" (hohe Keyword-Überlappung, aber wenig Inhalt)\n",
    "- Dokument B: \"Algorithmen trainieren Modelle anhand von Daten, um Muster zu erkennen\" (erklärt das Konzept, aber weniger Keywords)\n",
    "\n",
    "Vector Search könnte Dokument A höher ranken, aber Dokument B ist relevanter!\n",
    "\n",
    "### Lösung: CrossEncoder Reranking\n",
    "\n",
    "Ein **CrossEncoder** verarbeitet Query und Dokument **gemeinsam** als Paar:\n",
    "- Eingabe: `[QUERY, DOKUMENT]` als zusammenhängender Text\n",
    "- Ausgabe: Ein **Relevanz-Score** zwischen -∞ und +∞\n",
    "  - **Positive Scores** (z.B. +4.0): Dokument ist relevant für die Query\n",
    "  - **Scores nahe 0** (z.B. -0.5 bis +0.5): Moderate oder unsichere Relevanz\n",
    "  - **Negative Scores** (z.B. -11.0): Dokument ist irrelevant für die Query\n",
    "  - Die **absoluten Werte** sind weniger wichtig als die **relative Reihenfolge**\n",
    "- Vorteil: Kann die **semantische Beziehung** zwischen Query und Dokument besser verstehen\n",
    "\n",
    "**Trade-offs:**\n",
    "- ✅ Höhere Qualität der Ergebnisse\n",
    "- ✅ Bessere semantische Relevanz\n",
    "- ❌ Langsamer (O(n) statt O(1) wie Vector Search)\n",
    "- ❌ Kann nur auf kleine Dokumentenmengen angewendet werden\n",
    "\n",
    "Daher nutzen wir die **zweistufige Strategie**: Erst schnell viele Kandidaten finden, dann präzise reranken!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Beispiel-Dokumentensammlung\n",
    "\n",
    "Wir verwenden die andrena-Dokumentensammlung aus der Hybrid Search Übung. Diese zeigt das **Homonym-Problem**: \"andrena\" kann sowohl die Softwarefirma **andrena objects** als auch die Wildbienen-Gattung **Andrena** bezeichnen. Ideal, um zu demonstrieren, wie Reranking die Query-Intention besser versteht!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T20:01:20.020945Z",
     "start_time": "2025-10-23T20:01:19.966768Z"
    }
   },
   "source": "from langchain_core.documents import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_chroma import Chroma\nimport os\n\n# Beispiel-Dokumente über andrena objects (Firma) und Andrena (Wildbienen)\n# Dieses Homonym-Problem ist ideal, um die Stärken von Reranking zu demonstrieren\ndocuments = [\n    # andrena objects - Softwarefirma (5 Dokumente)\n    Document(\n        page_content=\"andrena objects ist eine Softwareentwicklungsfirma mit Sitz in Karlsruhe, die sich auf agile Entwicklungsmethoden und Clean Code spezialisiert hat.\",\n        metadata={\"id\": \"doc1\", \"topic\": \"andrena-objects\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"andrena objects bietet Dienstleistungen in den Bereichen Software-Entwicklung, Consulting, Coaching und Training für agile Methoden an.\",\n        metadata={\"id\": \"doc2\", \"topic\": \"andrena-objects\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"Das Team von andrena objects besteht aus erfahrenen Software-Entwicklern, die Wert auf Qualität und handwerkliches Können legen.\",\n        metadata={\"id\": \"doc3\", \"topic\": \"andrena-objects\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"andrena objects setzt auf moderne Technologien wie Java, Python, TypeScript und Cloud-native Architekturen für Kundenprojekte.\",\n        metadata={\"id\": \"doc4\", \"topic\": \"andrena-objects\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"Die Unternehmenskultur bei andrena objects fördert kontinuierliches Lernen, Pair Programming und Test-Driven Development.\",\n        metadata={\"id\": \"doc5\", \"topic\": \"andrena-objects\", \"category\": \"company\"}\n    ),\n\n    # Andrena - Wildbienen (6 Dokumente)\n    Document(\n        page_content=\"Andrena ist eine Gattung von Wildbienen, die auch als Sandbienen oder Erdbienen bekannt sind und weltweit verbreitet vorkommen.\",\n        metadata={\"id\": \"doc6\", \"topic\": \"andrena-bees\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"Sandbienen der Gattung Andrena nisten in selbstgegrabenen Röhren im Boden und sind wichtige Bestäuber für Obstbäume und Wildpflanzen.\",\n        metadata={\"id\": \"doc7\", \"topic\": \"andrena-bees\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"Die Andrena-Arten sind durch ihre pelzige Behaarung und die Fähigkeit gekennzeichnet, Pollen in speziellen Haarbürsten zu sammeln.\",\n        metadata={\"id\": \"doc8\", \"topic\": \"andrena-bees\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"In Deutschland gibt es über 100 verschiedene Andrena-Arten, die von März bis September aktiv sind und bevorzugt sandige Böden besiedeln.\",\n        metadata={\"id\": \"doc9\", \"topic\": \"andrena-bees\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"Andrena-Weibchen legen Brutzellen an, in denen sie Pollen und Nektar für ihre Nachkommen sammeln, bevor sie ein Ei ablegen.\",\n        metadata={\"id\": \"doc10\", \"topic\": \"andrena-bees\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"Die meisten Andrena-Arten sind oligolektisch, das heißt sie sammeln Pollen nur von bestimmten Pflanzenfamilien wie Weiden oder Kreuzblütlern.\",\n        metadata={\"id\": \"doc11\", \"topic\": \"andrena-bees\", \"category\": \"bees\"}\n    ),\n\n    # Andere Softwarefirmen (5 Dokumente)\n    Document(\n        page_content=\"ThoughtWorks ist eine globale Softwareberatung, die sich auf agile Transformation und maßgeschneiderte Software-Lösungen konzentriert.\",\n        metadata={\"id\": \"doc12\", \"topic\": \"other-companies\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"Netlight Consulting bietet IT-Beratung und Software-Entwicklung mit Fokus auf digitale Transformation und Innovation in Skandinavien und Europa.\",\n        metadata={\"id\": \"doc13\", \"topic\": \"other-companies\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"INNOQ ist eine deutsche IT-Beratungsfirma, die sich auf Architektur-Beratung, Entwicklung und Technologie-Strategie spezialisiert hat.\",\n        metadata={\"id\": \"doc14\", \"topic\": \"other-companies\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"it-agile aus Hamburg bietet Schulungen, Coaching und Beratung für Scrum, Kanban und andere agile Frameworks an.\",\n        metadata={\"id\": \"doc15\", \"topic\": \"other-companies\", \"category\": \"company\"}\n    ),\n    Document(\n        page_content=\"Zühlke Engineering ist ein internationales Dienstleistungsunternehmen für Innovation und Software-Entwicklung mit Schweizer Wurzeln.\",\n        metadata={\"id\": \"doc16\", \"topic\": \"other-companies\", \"category\": \"company\"}\n    ),\n\n    # Andere Insekten (4 Dokumente)\n    Document(\n        page_content=\"Honigbienen der Art Apis mellifera leben in Staaten mit bis zu 50000 Individuen und produzieren Honig als Wintervorrat.\",\n        metadata={\"id\": \"doc17\", \"topic\": \"other-insects\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"Hummeln gehören zur Gattung Bombus und sind robuste Bestäuber, die auch bei kühlen Temperaturen fliegen können.\",\n        metadata={\"id\": \"doc18\", \"topic\": \"other-insects\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"Solitäre Wespen wie die Grabwespen graben Nester im Boden und versorgen ihre Larven mit gelähmten Insekten als Nahrung.\",\n        metadata={\"id\": \"doc19\", \"topic\": \"other-insects\", \"category\": \"bees\"}\n    ),\n    Document(\n        page_content=\"Schwebfliegen imitieren das Aussehen von Bienen und Wespen, sind aber harmlose Blütenbesucher und wichtige Bestäuber.\",\n        metadata={\"id\": \"doc20\", \"topic\": \"other-insects\", \"category\": \"bees\"}\n    ),\n\n    # IT-Themen allgemein (5 Dokumente)\n    Document(\n        page_content=\"Test-Driven Development ist eine Entwicklungsmethode, bei der Tests vor dem eigentlichen Code geschrieben werden.\",\n        metadata={\"id\": \"doc21\", \"topic\": \"it-general\", \"category\": \"tech\"}\n    ),\n    Document(\n        page_content=\"Microservices-Architekturen zerlegen Anwendungen in kleine, unabhängig deploybare Services mit klaren Schnittstellen.\",\n        metadata={\"id\": \"doc22\", \"topic\": \"it-general\", \"category\": \"tech\"}\n    ),\n    Document(\n        page_content=\"Domain-Driven Design ist ein Ansatz zur Modellierung komplexer Software-Systeme basierend auf der Fachdomäne.\",\n        metadata={\"id\": \"doc23\", \"topic\": \"it-general\", \"category\": \"tech\"}\n    ),\n    Document(\n        page_content=\"Continuous Integration und Continuous Deployment automatisieren den Build- und Deployment-Prozess für schnellere Releases.\",\n        metadata={\"id\": \"doc24\", \"topic\": \"it-general\", \"category\": \"tech\"}\n    ),\n    Document(\n        page_content=\"Pair Programming ist eine agile Praxis, bei der zwei Entwickler gemeinsam an einem Computer arbeiten und Code schreiben.\",\n        metadata={\"id\": \"doc25\", \"topic\": \"it-general\", \"category\": \"tech\"}\n    ),\n]\n\nprint(f\"Erstellt {len(documents)} Dokumente\")\nprint(\"\\nBeispiel-Dokument:\")\nprint(f\"ID: {documents[0].metadata['id']}\")\nprint(f\"Content: {documents[0].page_content}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstellt 25 Dokumente\n",
      "\n",
      "Beispiel-Dokument:\n",
      "ID: doc1\n",
      "Content: andrena objects ist eine Softwareentwicklungsfirma mit Sitz in Karlsruhe, die sich auf agile Entwicklungsmethoden und Clean Code spezialisiert hat.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 1: Retrieval OHNE Reranking\n",
    "\n",
    "Zuerst schauen wir uns an, wie ein normaler Vector Search funktioniert und wo seine Limitationen liegen."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T20:01:21.160077Z",
     "start_time": "2025-10-23T20:01:20.047963Z"
    }
   },
   "source": [
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Erstelle Vector Store mit Embeddings\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "# Erstelle einen neuen ephemeral client, um Duplikate bei mehrfacher Ausführung des Notebooks zu vermeiden\n",
    "client = chromadb.EphemeralClient()\n",
    "try:\n",
    "    client.delete_collection(\"reranking_demo\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Erstelle Chroma Vector Store\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"reranking_demo\",\n",
    "    client=client\n",
    ")\n",
    "\n",
    "print(\"✓ Vector Store erstellt\")\n",
    "print(f\"  Anzahl Dokumente: {len(documents)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vector Store erstellt\n",
      "  Anzahl Dokumente: 25\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T20:01:21.527645Z",
     "start_time": "2025-10-23T20:01:21.192619Z"
    }
   },
   "source": "# Query: Wir wollen Informationen über die Softwarefirma andrena objects\nquery = \"wie entwickelt andrena?\"\n\n# Retrieval mit Similarity Search (k=5 Dokumente)\nresults_without_reranking = vector_store.similarity_search_with_score(query, k=7)\n\nprint(f\"Query: '{query}'\")\nprint(\"\\n\" + \"=\"*80)\nprint(\"ERGEBNISSE OHNE RERANKING (Vector Similarity)\")\nprint(\"=\"*80 + \"\\n\")\n\nfor rank, (doc, score) in enumerate(results_without_reranking, 1):\n    print(f\"Rang {rank} | Similarity: {score:.4f} | ID: {doc.metadata['id']}\")\n    print(f\"Content: {doc.page_content}\")\n    print(\"-\" * 80)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'wie entwickelt andrena?'\n",
      "\n",
      "================================================================================\n",
      "ERGEBNISSE OHNE RERANKING (Vector Similarity)\n",
      "================================================================================\n",
      "\n",
      "Rang 1 | Similarity: 0.7349 | ID: doc1\n",
      "Content: andrena objects ist eine Softwareentwicklungsfirma mit Sitz in Karlsruhe, die sich auf agile Entwicklungsmethoden und Clean Code spezialisiert hat.\n",
      "--------------------------------------------------------------------------------\n",
      "Rang 2 | Similarity: 0.7495 | ID: doc6\n",
      "Content: Andrena ist eine Gattung von Wildbienen, die auch als Sandbienen oder Erdbienen bekannt sind und weltweit verbreitet vorkommen.\n",
      "--------------------------------------------------------------------------------\n",
      "Rang 3 | Similarity: 0.8300 | ID: doc10\n",
      "Content: Andrena-Weibchen legen Brutzellen an, in denen sie Pollen und Nektar für ihre Nachkommen sammeln, bevor sie ein Ei ablegen.\n",
      "--------------------------------------------------------------------------------\n",
      "Rang 4 | Similarity: 0.8421 | ID: doc9\n",
      "Content: In Deutschland gibt es über 100 verschiedene Andrena-Arten, die von März bis September aktiv sind und bevorzugt sandige Böden besiedeln.\n",
      "--------------------------------------------------------------------------------\n",
      "Rang 5 | Similarity: 0.8685 | ID: doc8\n",
      "Content: Die Andrena-Arten sind durch ihre pelzige Behaarung und die Fähigkeit gekennzeichnet, Pollen in speziellen Haarbürsten zu sammeln.\n",
      "--------------------------------------------------------------------------------\n",
      "Rang 6 | Similarity: 0.9372 | ID: doc2\n",
      "Content: andrena objects bietet Dienstleistungen in den Bereichen Software-Entwicklung, Consulting, Coaching und Training für agile Methoden an.\n",
      "--------------------------------------------------------------------------------\n",
      "Rang 7 | Similarity: 0.9413 | ID: doc3\n",
      "Content: Das Team von andrena objects besteht aus erfahrenen Software-Entwicklern, die Wert auf Qualität und handwerkliches Können legen.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Beobachtung: Was ist das Problem?\n\nSchaue dir die Ergebnisse genau an:\n\n**Query:** \"wie entwickelt andrena?\"\n\nDie Frage zielt eindeutig auf die **Softwarefirma andrena objects** und deren Entwicklungsmethoden ab, nicht auf die biologische Entwicklung von Wildbienen.\n\n**Probleme mit Vector Search:**\n1. Dokumente mit **Keyword-Überlappung** (\"andrena\", \"entwickelt\") werden hoch gerankt - egal ob Firma oder Bienen\n2. Vector Search erfasst nicht die **Query-Intention** (Software-Entwicklung vs. biologische Entwicklung)\n3. **Bienen-Dokumente** werden zurückgegeben (siehe Rang 2-5), obwohl sie im Kontext von Software-Entwicklung irrelevant sind\n\n**Das Homonym-Problem:**\n- \"andrena\" alleine ist mehrdeutig (Firma oder Bienen-Gattung)\n- \"entwickelt\" kann sich auf Software-Entwicklung ODER biologische Entwicklung beziehen\n- Vector Search kann die richtige Bedeutung nicht aus dem Kontext ableiten\n\n→ **Reranking kann helfen**, weil der CrossEncoder Query und Dokument **gemeinsam** verarbeitet und die Intention besser versteht!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 2: Retrieval MIT Reranking (CrossEncoder)\n",
    "\n",
    "Jetzt wenden wir Reranking auf die gleichen Ergebnisse an und schauen, wie sich die Reihenfolge ändert.\n",
    "\n",
    "**Hinweis:** Falls das Laden des Modells im nächsten Code-Block hängt, führe diesen Befehl im Terminal aus:\n",
    "```bash\n",
    "source .venv/bin/activate && python -c \"from sentence_transformers import CrossEncoder; CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T20:01:23.953962Z",
     "start_time": "2025-10-23T20:01:21.576779Z"
    }
   },
   "source": "from sentence_transformers import CrossEncoder\n\n# Lade CrossEncoder Modell\n# Dieses Modell wurde speziell trainiert, um Query-Document Relevanz zu bewerten\ncross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)\n\nprint(\"✓ CrossEncoder Modell geladen\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CrossEncoder Modell geladen\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-23T20:06:07.619182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reranking: Berechne CrossEncoder Scores für alle Dokumente\n",
    "print(f\"Bereite {len(results_without_reranking)} Dokumente für Reranking vor...\")\n",
    "query_document_pairs = [(query, doc.page_content) for doc, _ in results_without_reranking]\n",
    "\n",
    "print(f\"Berechne CrossEncoder Scores für {len(query_document_pairs)} Query-Document Paare...\")\n",
    "# CrossEncoder gibt einen Relevanz-Score zurück\n",
    "reranking_scores = cross_encoder.predict(query_document_pairs)\n",
    "print(\"✓ CrossEncoder Scores berechnet\")\n",
    "\n",
    "# Kombiniere Dokumente mit neuen Scores\n",
    "reranked_results = [\n",
    "    (doc, original_score, rerank_score)\n",
    "    for (doc, original_score), rerank_score in zip(results_without_reranking, reranking_scores)\n",
    "]\n",
    "\n",
    "# Sortiere nach Reranking-Score (höher = besser)\n",
    "reranked_results = sorted(reranked_results, key=lambda x: x[2], reverse=True)\n",
    "print(\"✓ Ergebnisse neu sortiert\\n\")\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ERGEBNISSE MIT RERANKING (CrossEncoder)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for rank, (doc, original_score, rerank_score) in enumerate(reranked_results, 1):\n",
    "    print(f\"Rang {rank} | CrossEncoder: {rerank_score:.4f} | Original Similarity: {original_score:.4f} | ID: {doc.metadata['id']}\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(\"-\" * 80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bereite 7 Dokumente für Reranking vor...\n",
      "Berechne CrossEncoder Scores für 7 Query-Document Paare...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beobachtung: Was hat sich geändert?\n",
    "\n",
    "Vergleiche die Rankings vorher und nachher:\n",
    "\n",
    "**Achte auf:**\n",
    "1. Welche Dokumente haben sich nach oben bewegt?\n",
    "2. Welche Dokumente haben sich nach unten bewegt?\n",
    "3. Warum macht das Sinn in Bezug auf die Query?\n",
    "\n",
    "**Erwartetes Verhalten:**\n",
    "- **andrena objects Firma-Dokumente** sollten ganz oben sein (höchste Relevanz für die Query)\n",
    "- **Andrena Bienen-Dokumente** sollten nach unten rutschen oder ganz verschwinden (irrelevant für die Query)\n",
    "- **Andere Firmen-Dokumente** könnten niedrig gerankt werden (thematisch ähnlich, aber nicht die gesuchte Firma)\n",
    "- Der CrossEncoder versteht, dass \"andrena objects\" **als Ganzes** die Firma bezeichnet, nicht nur \"andrena\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich: Vorher vs. Nachher\n",
    "\n",
    "Visualisieren wir die Unterschiede zwischen Vector Search und Reranking."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T20:03:18.200390Z",
     "start_time": "2025-10-23T20:03:18.177246Z"
    }
   },
   "source": "import pandas as pd\n\n# Erstelle Vergleichstabelle\ncomparison_data = []\n\nfor rank, (doc, original_score) in enumerate(results_without_reranking, 1):\n    doc_id = doc.metadata['id']\n    # Finde das Dokument in den reranked results\n    reranked_rank = next(i for i, (d, _, _) in enumerate(reranked_results, 1) if d.metadata['id'] == doc_id)\n    rerank_score = next(score for d, _, score in reranked_results if d.metadata['id'] == doc_id)\n    \n    comparison_data.append({\n        'Doc ID': doc_id,\n        'Content (Auszug)': doc.page_content[:50] + '...',\n        'Rank OHNE Reranking': rank,\n        'Vector Similarity': f\"{original_score:.4f}\",\n        'Rank MIT Reranking': reranked_rank,\n        'CrossEncoder Score': f\"{rerank_score:.4f}\",\n        'Rang-Änderung': f\"{rank - reranked_rank:+d}\"\n    })\n\ndf = pd.DataFrame(comparison_data)\nprint(\"\\n\" + \"=\"*120)\nprint(\"VERGLEICH: Vector Search vs. Reranking\")\nprint(\"=\"*120)\nprint(df.to_string(index=False))\nprint(\"\\n📊 Positive Rang-Änderung = Dokument ist nach oben gerutscht\")\nprint(\"📊 Negative Rang-Änderung = Dokument ist nach unten gerutscht\")",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reranked_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m doc_id = doc.metadata[\u001B[33m'\u001B[39m\u001B[33mid\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Finde das Dokument in den reranked results\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m reranked_rank = \u001B[38;5;28mnext\u001B[39m(i \u001B[38;5;28;01mfor\u001B[39;00m i, (d, _, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mreranked_results\u001B[49m, \u001B[32m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m d.metadata[\u001B[33m'\u001B[39m\u001B[33mid\u001B[39m\u001B[33m'\u001B[39m] == doc_id)\n\u001B[32m     10\u001B[39m rerank_score = \u001B[38;5;28mnext\u001B[39m(score \u001B[38;5;28;01mfor\u001B[39;00m d, _, score \u001B[38;5;129;01min\u001B[39;00m reranked_results \u001B[38;5;28;01mif\u001B[39;00m d.metadata[\u001B[33m'\u001B[39m\u001B[33mid\u001B[39m\u001B[33m'\u001B[39m] == doc_id)\n\u001B[32m     12\u001B[39m comparison_data.append({\n\u001B[32m     13\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mDoc ID\u001B[39m\u001B[33m'\u001B[39m: doc_id,\n\u001B[32m     14\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mContent (Auszug)\u001B[39m\u001B[33m'\u001B[39m: doc.page_content[:\u001B[32m50\u001B[39m] + \u001B[33m'\u001B[39m\u001B[33m...\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     19\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mRang-Änderung\u001B[39m\u001B[33m'\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrank\u001B[38;5;250m \u001B[39m-\u001B[38;5;250m \u001B[39mreranked_rank\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m+d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     20\u001B[39m })\n",
      "\u001B[31mNameError\u001B[39m: name 'reranked_results' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übung 2: CONTEXT_SIZE_AFTER_RERANKING Parameter\n",
    "\n",
    "Nach dem Reranking behalten wir nur die **top K besten Dokumente**, um das Context Window zu reduzieren und Kosten zu sparen.\n",
    "\n",
    "**Vorteile:**\n",
    "- Weniger Tokens ans LLM (Kostenersparnis)\n",
    "- Nur die relevantesten Dokumente\n",
    "- Entfernung von irrelevantem Noise\n",
    "\n",
    "Schauen wir uns an, wie sich verschiedene Werte für `CONTEXT_SIZE_AFTER_RERANKING` auswirken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def test_context_size_after_reranking(query, initial_k=8, context_size_after=3):\n    \"\"\"\n    Zeigt den Effekt von CONTEXT_SIZE_AFTER_RERANKING\n    \"\"\"\n    # Initial Retrieval (viele Dokumente)\n    results = vector_store.similarity_search_with_score(query, k=initial_k)\n    \n    # Reranking\n    query_document_pairs = [(query, doc.page_content) for doc, _ in results]\n    reranking_scores = cross_encoder.predict(query_document_pairs)\n    \n    reranked = [\n        (doc, original_score, rerank_score) \n        for (doc, original_score), rerank_score in zip(results, reranking_scores)\n    ]\n    reranked = sorted(reranked, key=lambda x: x[2], reverse=True)\n    \n    # Behalte nur top K nach Reranking\n    final_context = reranked[:context_size_after]\n    \n    print(f\"\\nQuery: '{query}'\")\n    print(f\"\\nPipeline: Initial Retrieval (k={initial_k}) → Reranking → Keep Top {context_size_after}\")\n    print(\"\\n\" + \"=\"*80)\n    print(\"FINALE DOKUMENTE FÜR DAS LLM:\")\n    print(\"=\"*80 + \"\\n\")\n    \n    for rank, (doc, original_score, rerank_score) in enumerate(final_context, 1):\n        print(f\"Rang {rank} | CrossEncoder: {rerank_score:.4f} | ID: {doc.metadata['id']}\")\n        print(f\"Content: {doc.page_content}\")\n        print(\"-\" * 80)\n    \n    print(f\"\\n📝 Von {initial_k} initial abgerufenen Dokumenten werden {context_size_after} ans LLM weitergegeben.\")\n    print(f\"💰 Token-Reduktion: ~{((initial_k - context_size_after) / initial_k * 100):.0f}% weniger Context\")\n\n# Teste verschiedene Werte\ntest_context_size_after_reranking(\n    query=\"Wie entwickelt andrena?\",\n    initial_k=8,\n    context_size_after=5\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Experiment: Weniger Dokumente behalten (sehr restriktiv)\ntest_context_size_after_reranking(\n    query=\"Wie entwickelt andrena?\",\n    initial_k=10,\n    context_size_after=2\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Experiment: Mehr Dokumente behalten\ntest_context_size_after_reranking(\n    query=\"Wie entwickelt andrena?\",\n    initial_k=15,\n    context_size_after=5\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beobachtung:\n",
    "\n",
    "**Trade-off bei CONTEXT_SIZE_AFTER_RERANKING:**\n",
    "\n",
    "**Kleinerer Wert (z.B. 2-3):**\n",
    "- ✅ Weniger Tokens ans LLM → **Kostenersparnis**\n",
    "- ✅ Nur die relevantesten Dokumente → **Höhere Precision**\n",
    "- ❌ Risiko wichtige Informationen zu verlieren → **Niedrigere Recall**\n",
    "\n",
    "**Größerer Wert (z.B. 5-6):**\n",
    "- ✅ Mehr Kontext für das LLM → **Höhere Recall**\n",
    "- ✅ Mehr Sicherheit, relevante Infos einzuschließen\n",
    "- ❌ Mehr Tokens → **Höhere Kosten**\n",
    "- ❌ Mehr potentiell irrelevante Dokumente → **Niedrigere Precision**\n",
    "\n",
    "→ Wähle den Wert basierend auf deinem Use-Case und Budget!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranking im RAG-System aktivieren\n",
    "\n",
    "Nachdem du Reranking in diesem Notebook getestet hast, möchtest du es jetzt in deinem echten RAG-System aktivieren.\n",
    "\n",
    "### Schritt 1: `.env` Datei anpassen\n",
    "\n",
    "Öffne die `.env` Datei im Projekt-Root und setze folgende Variablen:\n",
    "\n",
    "```bash\n",
    "# Reranking aktivieren\n",
    "USE_RERANKING=true\n",
    "\n",
    "# CrossEncoder Modell (empfohlen für Deutsch/Englisch)\n",
    "CROSS_ENCODER=cross-encoder/ms-marco-MiniLM-L-12-v2\n",
    "\n",
    "# Anzahl Dokumente nach Reranking (experimentiere mit 2-6)\n",
    "CONTEXT_SIZE_AFTER_RERANKING=4\n",
    "\n",
    "# Stelle sicher, dass initial genug Dokumente abgerufen werden\n",
    "RETRIEVED_NUMBER_OF_DOCUMENTS=10\n",
    "```\n",
    "\n",
    "### Schritt 2: Backend neu starten\n",
    "\n",
    "Starte das Backend neu, damit die Änderungen wirksam werden:\n",
    "\n",
    "```bash\n",
    "uv run --env-file .env python -m src.advanced_rag.backend.main\n",
    "```\n",
    "\n",
    "### Schritt 3: Teste im Frontend\n",
    "\n",
    "Öffne die Web-UI und stelle Fragen. Du solltest sehen:\n",
    "- Bessere Relevanz der Antworten\n",
    "- Weniger irrelevante Dokumente im Context\n",
    "\n",
    "**Tipp:** Vergleiche die gleiche Frage mit `USE_RERANKING=false` und `USE_RERANKING=true`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Reranking quantitativ bewerten\n",
    "\n",
    "Um objektiv zu messen, ob Reranking die Qualität verbessert, führen wir eine systematische Evaluation durch.\n",
    "\n",
    "### Schritt-für-Schritt Evaluation\n",
    "\n",
    "#### 1. Baseline: OHNE Reranking evaluieren\n",
    "\n",
    "Setze in der `.env` Datei:\n",
    "\n",
    "```bash\n",
    "USE_RERANKING=false\n",
    "RETRIEVED_NUMBER_OF_DOCUMENTS=4\n",
    "```\n",
    "\n",
    "Starte das Backend:\n",
    "```bash\n",
    "uv run --env-file .env python -m src.advanced_rag.backend.main\n",
    "```\n",
    "\n",
    "Führe die Evaluation aus (in einem neuen Terminal):\n",
    "```bash\n",
    "uv run --env-file .env python src/advanced_rag/evaluation/evaluate_dataset.py\n",
    "```\n",
    "\n",
    "**Notiere die Scores aus Langfuse:**\n",
    "- Context Precision: ?\n",
    "- Context Recall: ?\n",
    "- Answer Relevancy: ?\n",
    "- Faithfulness: ?\n",
    "\n",
    "#### 2. MIT Reranking evaluieren\n",
    "\n",
    "Setze in der `.env` Datei:\n",
    "\n",
    "```bash\n",
    "USE_RERANKING=true\n",
    "CROSS_ENCODER=cross-encoder/ms-marco-MiniLM-L-12-v2\n",
    "RETRIEVED_NUMBER_OF_DOCUMENTS=10  # Initial mehr abrufen\n",
    "CONTEXT_SIZE_AFTER_RERANKING=4    # Dann auf 4 reduzieren\n",
    "```\n",
    "\n",
    "Backend neu starten und Evaluation erneut ausführen.\n",
    "\n",
    "**Notiere die Scores aus Langfuse:**\n",
    "- Context Precision: ?\n",
    "- Context Recall: ?\n",
    "- Answer Relevancy: ?\n",
    "- Faithfulness: ?\n",
    "\n",
    "#### 3. Ergebnisse vergleichen\n",
    "\n",
    "Trage deine Ergebnisse in diese Tabelle ein:\n",
    "\n",
    "| Metrik              | OHNE Reranking | MIT Reranking | Verbesserung |\n",
    "|---------------------|----------------|---------------|---------------|\n",
    "| Context Precision   |       ?        |       ?       |      ?%       |\n",
    "| Context Recall      |       ?        |       ?       |      ?%       |\n",
    "| Answer Relevancy    |       ?        |       ?       |      ?%       |\n",
    "| Faithfulness        |       ?        |       ?       |      ?%       |\n",
    "\n",
    "### Erwartete Ergebnisse:\n",
    "\n",
    "**Context Precision sollte steigen:**\n",
    "- Reranking entfernt irrelevante Dokumente aus dem Context\n",
    "- Nur die semantisch relevantesten Dokumente bleiben übrig\n",
    "\n",
    "**Context Recall könnte leicht sinken:**\n",
    "- Durch CONTEXT_SIZE_AFTER_RERANKING werden Dokumente entfernt\n",
    "- Manchmal enthält ein entferntes Dokument relevante Informationen\n",
    "\n",
    "**Answer Relevancy sollte steigen:**\n",
    "- Besserer Context führt zu besseren Antworten\n",
    "- Das LLM wird nicht durch irrelevante Infos abgelenkt\n",
    "\n",
    "**Faithfulness könnte steigen:**\n",
    "- Weniger irrelevanter Context reduziert Halluzinationen\n",
    "- Das LLM bezieht sich auf die wirklich relevanten Dokumente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "### Was hast du gelernt?\n",
    "\n",
    "1. **Reranking ist eine zweistufige Retrieval-Strategie:**\n",
    "   - Erste Stufe: Schneller Vector Search mit vielen Kandidaten\n",
    "   - Zweite Stufe: Präzises Reranking mit CrossEncoder\n",
    "\n",
    "2. **CrossEncoder vs. Vector Search:**\n",
    "   - CrossEncoder verarbeitet Query und Dokument gemeinsam\n",
    "   - Erfasst semantische Relevanz besser als Cosine-Similarity\n",
    "   - Langsamer, aber qualitativ hochwertiger\n",
    "\n",
    "3. **CONTEXT_SIZE_AFTER_RERANKING:**\n",
    "   - Trade-off zwischen Recall (mehr Dokumente) und Precision (bessere Qualität)\n",
    "   - Experimentiere mit verschiedenen Werten für deinen Use-Case\n",
    "\n",
    "4. **Evaluation ist wichtig:**\n",
    "   - Vergleiche Metriken mit und ohne Reranking\n",
    "   - Context Precision sollte deutlich steigen\n",
    "   - Answer Relevancy sollte sich verbessern\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- ✅ Rufe initial mehr Dokumente ab als du final brauchst (z.B. 10 → Rerank → 4)\n",
    "- ✅ Nutze kleinere CrossEncoder Modelle in Produktion für bessere Latenz\n",
    "- ✅ Evaluiere systematisch mit echten Test-Queries\n",
    "- ✅ Monitore die Latenz - Reranking fügt 50-200ms hinzu\n",
    "- ✅ Experimentiere mit CONTEXT_SIZE_AFTER_RERANKING basierend auf deinem Use-Case\n",
    "\n",
    "### Weiterführende Fragen:\n",
    "\n",
    "- Wann lohnt sich Reranking? (Immer bei komplexen Queries!)\n",
    "- Gibt es Alternativen? (Ja: ColBERT, late interaction models)\n",
    "- Kann man Reranking mehrfach anwenden? (Ja, aber mit diminishing returns)\n",
    "\n",
    "Viel Erfolg beim Optimieren deines RAG-Systems! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced-rag (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
