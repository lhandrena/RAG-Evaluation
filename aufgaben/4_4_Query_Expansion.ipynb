{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Expansion - Verbesserte Retrieval-Abdeckung durch Multiple Queries\n",
    "\n",
    "## Was ist Query Expansion?\n",
    "\n",
    "Query Expansion ist eine **Technik zur Verbesserung des Retrievals** in RAG-Systemen:\n",
    "\n",
    "- **Problem**: Eine einzelne User-Query kann wichtige relevante Dokumente verpassen\n",
    "- **LÃ¶sung**: Generiere mehrere semantisch Ã¤hnliche Query-Varianten und suche mit allen gleichzeitig\n",
    "- **Resultat**: Breitere Abdeckung relevanter Dokumente durch verschiedene Formulierungen\n",
    "\n",
    "### Warum ist Query Expansion wichtig?\n",
    "\n",
    "**Problem mit Single-Query Retrieval:**\n",
    "- Nutzer formulieren Fragen oft **unvollstÃ¤ndig oder unprÃ¤zise**\n",
    "- Dokumente verwenden mÃ¶glicherweise **andere Begriffe oder Synonyme**\n",
    "- Eine einzelne Query erfasst nicht alle **semantischen Perspektiven** einer Frage\n",
    "\n",
    "**Beispiel (aus dem Haystack Tutorial):**\n",
    "- Original Query: \"green energy sources\"\n",
    "- Expanded Queries:\n",
    "  - \"renewable energy sources\"\n",
    "  - \"sustainable power generation\"\n",
    "  - \"eco-friendly energy options\"\n",
    "  - \"clean energy resources\"\n",
    "\n",
    "Jede dieser Varianten kann **andere relevante Dokumente** finden, die die Original-Query verpasst hÃ¤tte!\n",
    "\n",
    "### LÃ¶sung: MultiQueryRetriever\n",
    "\n",
    "Der **LangChain MultiQueryRetriever** automatisiert Query Expansion:\n",
    "- Nutzt ein LLM, um automatisch mehrere Query-Varianten zu generieren\n",
    "- FÃ¼hrt Retrieval fÃ¼r jede Variante durch\n",
    "- Dedupliziert und kombiniert die Ergebnisse\n",
    "- Liefert eine breitere Auswahl relevanter Dokumente\n",
    "\n",
    "**Trade-offs:**\n",
    "- âœ… HÃ¶here **Recall** (findet mehr relevante Dokumente)\n",
    "- âœ… Robuster gegenÃ¼ber ungenauen Nutzer-Queries\n",
    "- âœ… Erfasst verschiedene semantische Perspektiven\n",
    "- âŒ **Mehr API-Calls** (ein LLM-Call fÃ¼r Query-Generierung + mehrere Retrievals)\n",
    "- âŒ **HÃ¶here Latenz** durch zusÃ¤tzliche Schritte\n",
    "- âŒ Kann auch **irrelevante Dokumente** einschlieÃŸen\n",
    "\n",
    "Daher ist Query Expansion besonders nÃ¼tzlich bei **komplexen oder mehrdeutigen Queries**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Wikipedia Energie-Artikel laden\n",
    "\n",
    "Wir verwenden die gleichen Wikipedia-Artikel wie im [Haystack Query Expansion Tutorial](https://haystack.deepset.ai/cookbook/query-expansion):\n",
    "- **Renewable Energy**: Solar, Wind, Hydroelectricity, etc.\n",
    "- **Fossil Fuels**: Coal, Natural Gas, Oil\n",
    "- **Related Topics**: Electric Vehicles, Batteries, Greenhouse Gases\n",
    "\n",
    "Diese Artikel sind ideal, um Query Expansion zu demonstrieren, weil:\n",
    "- Viele **Synonyme** existieren (\"green energy\", \"renewable energy\", \"sustainable power\")\n",
    "- **Verschiedene Perspektiven** sind relevant (Technologie, Umwelt, Wirtschaft)\n",
    "- Queries kÃ¶nnen **unprÃ¤zise** sein (\"clean energy\" kÃ¶nnte Solar, Wind, oder Hydro meinen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "\n",
    "print(\"ðŸ“¥ Lade Wikipedia-Artikel...\")\n",
    "print(\"   Installiere wikipedia package falls nÃ¶tig: pip install wikipedia\")\n",
    "\n",
    "try:\n",
    "    import wikipedia\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  'wikipedia' package nicht gefunden!\")\n",
    "    print(\"   Installiere es mit: pip install wikipedia\")\n",
    "    raise\n",
    "\n",
    "# Liste der Wikipedia-Artikel (wie im Haystack Tutorial)\n",
    "article_titles = [\n",
    "    \"Electric_vehicle\",\n",
    "    \"Electric_battery\",\n",
    "    \"Solar_panel\",\n",
    "    \"Wind_power\",\n",
    "    \"Hydroelectricity\",\n",
    "    \"Nuclear_power\",\n",
    "    \"Coal\",\n",
    "    \"Natural_gas\",\n",
    "    \"Fossil_fuel\",\n",
    "    \"Renewable_energy\",\n",
    "    \"Greenhouse_gas\",\n",
    "    \"Dam\",\n",
    "    \"Tree\"\n",
    "]\n",
    "\n",
    "print(f\"   Lade {len(article_titles)} Artikel von Wikipedia...\\n\")\n",
    "\n",
    "# Lade Wikipedia-Inhalte\n",
    "raw_documents = []\n",
    "for title in article_titles:\n",
    "    try:\n",
    "        page = wikipedia.page(title, auto_suggest=False)\n",
    "        doc = Document(\n",
    "            page_content=page.content,\n",
    "            metadata={\n",
    "                \"source\": \"wikipedia\",\n",
    "                \"title\": title,\n",
    "                \"url\": page.url\n",
    "            }\n",
    "        )\n",
    "        raw_documents.append(doc)\n",
    "        print(f\"   âœ“ {title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— {title} - Fehler: {e}\")\n",
    "\n",
    "print(f\"\\nâœ“ {len(raw_documents)} Artikel erfolgreich geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunke die Dokumente in kleinere Abschnitte\n",
    "print(\"âœ‚ï¸  Chunke Dokumente...\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "print(f\"   âœ“ {len(documents)} Chunks erstellt aus {len(raw_documents)} Artikeln\")\n",
    "print(f\"   Durchschnittlich {len(documents) // len(raw_documents)} Chunks pro Artikel\")\n",
    "\n",
    "# Erstelle Vector Store mit Embeddings\n",
    "print(\"\\nðŸ”¢ Erstelle Embeddings und Vector Store...\")\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Erstelle einen neuen ephemeral client\n",
    "client = chromadb.EphemeralClient()\n",
    "\n",
    "# Erstelle Chroma Vector Store\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"query_expansion_demo\",\n",
    "    client=client\n",
    ")\n",
    "\n",
    "print(\"âœ“ Vector Store erstellt\")\n",
    "print(f\"  Anzahl Dokumente im Store: {len(documents)}\")\n",
    "print(f\"\\nðŸ“„ Beispiel-Dokument:\")\n",
    "print(f\"  Titel: {documents[0].metadata['title']}\")\n",
    "print(f\"  Content: {documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 1: Retrieval OHNE Query Expansion\n",
    "\n",
    "Zuerst schauen wir uns an, wie ein normaler Single-Query Retrieval funktioniert und wo seine Limitationen liegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Eine kurze, unprÃ¤zise Frage (wie im Haystack Tutorial)\n",
    "query = \"green energy sources\"\n",
    "\n",
    "# Retrieval mit Similarity Search (k=5 Dokumente)\n",
    "results_without_expansion = vector_store.similarity_search_with_score(query, k=5)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ERGEBNISSE OHNE QUERY EXPANSION (Single Query)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for rank, (doc, score) in enumerate(results_without_expansion, 1):\n",
    "    print(f\"Rang {rank} | Similarity: {score:.4f} | Artikel: {doc.metadata['title']}\")\n",
    "    print(f\"Content: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beobachtung: Was ist das Problem?\n",
    "\n",
    "Schaue dir die Ergebnisse genau an:\n",
    "\n",
    "**Query:** \"green energy sources\"\n",
    "\n",
    "Die Frage ist **unprÃ¤zise und kurz**. Was meint der Nutzer genau?\n",
    "- Solar Energy?\n",
    "- Wind Power?\n",
    "- Hydroelectricity?\n",
    "- Alle erneuerbaren Energien?\n",
    "\n",
    "**Probleme mit Single-Query Retrieval:**\n",
    "1. Die Query ist zu **unspezifisch** - \"green energy\" kann viele verschiedene Technologien bedeuten\n",
    "2. **Synonyme** werden nicht erfasst (\"renewable\", \"sustainable\", \"clean\", \"eco-friendly\")\n",
    "3. Verschiedene **semantische Perspektiven** werden nicht abgedeckt (Technologie vs. Umwelt vs. Wirtschaft)\n",
    "4. MÃ¶glicherweise werden wichtige relevante Dokumente **Ã¼bersehen**, weil sie andere Begriffe verwenden\n",
    "\n",
    "**Beispiele fÃ¼r verpasste Synonyme:**\n",
    "- \"green energy\" â‰  \"renewable energy\" (aber semantisch Ã¤hnlich)\n",
    "- \"sources\" â‰  \"power generation\", \"resources\", \"technologies\"\n",
    "- Spezifische Technologien wie \"solar\", \"wind\", \"hydro\" werden nicht direkt erwÃ¤hnt\n",
    "\n",
    "â†’ **Query Expansion kann helfen**, indem automatisch Varianten mit diesen Synonymen generiert werden!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 2: Retrieval MIT Query Expansion (MultiQueryRetriever)\n",
    "\n",
    "Jetzt verwenden wir den LangChain MultiQueryRetriever, um automatisch mehrere Query-Varianten zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Enable logging to see generated queries\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "# Erstelle LLM fÃ¼r Query-Generierung\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "# Erstelle MultiQueryRetriever\n",
    "# Dieser nutzt das LLM, um automatisch mehrere Query-Varianten zu generieren\n",
    "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "print(\"âœ“ MultiQueryRetriever erstellt\")\n",
    "print(\"  Das LLM wird automatisch mehrere Query-Varianten generieren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Expansion in Aktion\n",
    "# Der MultiQueryRetriever wird:\n",
    "# 1. Mehrere Query-Varianten generieren (siehst du im Log)\n",
    "# 2. FÃ¼r jede Variante ein Retrieval durchfÃ¼hren\n",
    "# 3. Alle Ergebnisse deduplizieren und kombinieren\n",
    "\n",
    "query = \"green energy sources\"\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ERGEBNISSE MIT QUERY EXPANSION (MultiQueryRetriever)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(\"â³ Generiere Query-Varianten und fÃ¼hre Retrieval durch...\\n\")\n",
    "\n",
    "# Invoke MultiQueryRetriever\n",
    "# Achte auf die Log-Ausgabe oben - dort siehst du die generierten Queries!\n",
    "results_with_expansion = multi_query_retriever.invoke(query)\n",
    "\n",
    "print(f\"\\nâœ“ Gefunden: {len(results_with_expansion)} eindeutige Dokumente\\n\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for rank, doc in enumerate(results_with_expansion, 1):\n",
    "    print(f\"Rang {rank} | Artikel: {doc.metadata['title']}\")\n",
    "    print(f\"Content: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beobachtung: Was hat sich geÃ¤ndert?\n",
    "\n",
    "Vergleiche die Ergebnisse vorher und nachher:\n",
    "\n",
    "**Achte auf:**\n",
    "1. **Anzahl der Dokumente**: Query Expansion findet oft mehr relevante Dokumente\n",
    "2. **DiversitÃ¤t**: Die Dokumente decken verschiedene Energie-Technologien ab (Solar, Wind, Hydro, etc.)\n",
    "3. **Generierte Queries** (siehe Log oben): Das LLM hat automatisch verschiedene Formulierungen erstellt\n",
    "\n",
    "**Erwartetes Verhalten:**\n",
    "- Mehr **relevante Dokumente** Ã¼ber erneuerbare Energien werden gefunden\n",
    "- **Verschiedene Technologien** werden abgedeckt (Solar, Wind, Hydroelectricity, Nuclear)\n",
    "- Das LLM hat Query-Varianten mit **Synonymen und Umformulierungen** erstellt\n",
    "- **HÃ¶herer Recall**: Weniger Chance, wichtige Dokumente zu Ã¼bersehen\n",
    "\n",
    "**MÃ¶gliche generierte Queries (Beispiele aus dem Haystack Tutorial):**\n",
    "- \"renewable energy sources\"\n",
    "- \"sustainable power generation\"\n",
    "- \"eco-friendly energy options\"\n",
    "- \"clean energy resources\"\n",
    "- \"alternative energy technologies\"\n",
    "\n",
    "**Warum ist das besser?**\n",
    "- **\"renewable\"** findet den \"Renewable_energy\" Artikel, der bei \"green\" vielleicht nicht top-ranked war\n",
    "- **\"sustainable\"** und **\"clean\"** erweitern das semantische Feld\n",
    "- **\"power generation\"** statt \"sources\" findet Dokumente mit anderen Formulierungen\n",
    "- Jede Query-Variante findet potenziell andere relevante Dokumente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 3: Vergleich und Analyse\n",
    "\n",
    "Schauen wir uns die Unterschiede systematisch an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dokumente aus beiden Methoden extrahieren\n",
    "single_query_doc_ids = {(doc.metadata['title'], doc.page_content[:100]) for doc, _ in results_without_expansion}\n",
    "multi_query_doc_ids = {(doc.metadata['title'], doc.page_content[:100]) for doc in results_with_expansion}\n",
    "\n",
    "# Analyse\n",
    "only_in_single = single_query_doc_ids - multi_query_doc_ids\n",
    "only_in_multi = multi_query_doc_ids - single_query_doc_ids\n",
    "in_both = single_query_doc_ids & multi_query_doc_ids\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERGLEICH: Single Query vs. Query Expansion\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"Dokumente OHNE Expansion (Single Query): {len(results_without_expansion)}\")\n",
    "print(f\"Dokumente MIT Expansion (Multi Query):   {len(results_with_expansion)}\")\n",
    "print(f\"\\nÃœberlappung (in beiden):                 {len(in_both)}\")\n",
    "print(f\"Nur in Single Query:                      {len(only_in_single)}\")\n",
    "print(f\"Nur in Multi Query:                       {len(only_in_multi)}\")\n",
    "\n",
    "if only_in_multi:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"NEU GEFUNDENE DOKUMENTE durch Query Expansion:\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    # Zeige neu gefundene Dokumente\n",
    "    multi_dict = {(doc.metadata['title'], doc.page_content[:100]): doc for doc in results_with_expansion}\n",
    "    \n",
    "    for key in only_in_multi:\n",
    "        doc = multi_dict[key]\n",
    "        print(f\"ðŸ“„ Artikel: {doc.metadata['title']}\")\n",
    "        print(f\"   Content: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "print(f\"\\nðŸ’¡ Query Expansion hat {len(only_in_multi)} neue relevante Dokumente gefunden!\")\n",
    "print(f\"   Das sind {len(only_in_multi) / len(results_without_expansion) * 100:.0f}% mehr Dokumente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 4: Custom Prompt fÃ¼r Query Expansion\n",
    "\n",
    "Der MultiQueryRetriever verwendet standardmÃ¤ÃŸig ein generisches Prompt. Du kannst aber ein **eigenes Prompt** definieren, um die Query-Generierung anzupassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from typing import List\n",
    "\n",
    "# Custom Output Parser: Konvertiert LLM-Output in eine Liste von Queries\n",
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a list of lines.\"\"\"\n",
    "    \n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "# Custom Prompt: Spezialisiert auf Energie-Themen\n",
    "CUSTOM_QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"Du bist ein Experte fÃ¼r Energie-Technologien und erneuerbare Energien.\n",
    "Deine Aufgabe ist es, alternative Formulierungen einer Nutzer-Frage zu generieren.\n",
    "\n",
    "Generiere 4 alternative Versionen der folgenden Frage.\n",
    "Die Fragen sollten verschiedene Perspektiven und Synonyme nutzen.\n",
    "Achte auf den Kontext von erneuerbaren Energien, Nachhaltigkeit, und Energie-Technologien.\n",
    "\n",
    "BerÃ¼cksichtige Synonyme wie:\n",
    "- \"green\" â†’ \"renewable\", \"sustainable\", \"clean\", \"eco-friendly\"\n",
    "- \"sources\" â†’ \"technologies\", \"power generation\", \"resources\", \"systems\"\n",
    "- Spezifische Technologien: Solar, Wind, Hydro, Nuclear, etc.\n",
    "\n",
    "Original-Frage: {question}\n",
    "\n",
    "Alternative Fragen (eine pro Zeile):\"\"\",\n",
    ")\n",
    "\n",
    "# Erstelle Custom LLM Chain\n",
    "output_parser = LineListOutputParser()\n",
    "llm_chain = CUSTOM_QUERY_PROMPT | llm | output_parser\n",
    "\n",
    "# Erstelle MultiQueryRetriever mit Custom Chain\n",
    "custom_multi_query_retriever = MultiQueryRetriever(\n",
    "    retriever=base_retriever,\n",
    "    llm_chain=llm_chain,\n",
    "    parser_key=\"lines\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Custom MultiQueryRetriever erstellt\")\n",
    "print(\"  Verwendet ein spezialisiertes Prompt fÃ¼r Energie-Themen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste den Custom Retriever\n",
    "query = \"green energy sources\"\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ERGEBNISSE MIT CUSTOM QUERY EXPANSION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(\"â³ Generiere Query-Varianten mit Custom Prompt...\\n\")\n",
    "\n",
    "results_custom = custom_multi_query_retriever.invoke(query)\n",
    "\n",
    "print(f\"\\nâœ“ Gefunden: {len(results_custom)} eindeutige Dokumente\\n\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for rank, doc in enumerate(results_custom, 1):\n",
    "    print(f\"Rang {rank} | Artikel: {doc.metadata['title']}\")\n",
    "    print(f\"Content: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beobachtung: Custom Prompt\n",
    "\n",
    "Vergleiche die generierten Queries (siehe Log) mit dem Standard-Prompt:\n",
    "\n",
    "**Custom Prompt Vorteile:**\n",
    "- âœ… **Domain-spezifisch**: Fokus auf Energie-Technologien und erneuerbare Energien\n",
    "- âœ… **Explizite Synonyme**: Prompt gibt konkrete Synonym-Beispiele (\"green\" â†’ \"renewable\", \"sustainable\")\n",
    "- âœ… **Kontrollierbar**: Du bestimmst den Stil und die Anzahl der Queries\n",
    "- âœ… **Bessere Relevanz**: Generierte Queries passen besser zur Energie-DomÃ¤ne\n",
    "\n",
    "**Vergleich der generierten Queries:**\n",
    "\n",
    "**Standard Prompt:**\n",
    "- Eher generisch und kÃ¶nnte beliebige Themen abdecken\n",
    "- Keine Domain-spezifischen Hinweise\n",
    "\n",
    "**Custom Prompt:**\n",
    "- Explizit auf Energie-Themen fokussiert\n",
    "- Gibt Synonym-Beispiele vor (\"renewable\", \"sustainable\", \"clean\")\n",
    "- ErwÃ¤hnt spezifische Technologien (Solar, Wind, Hydro)\n",
    "- FÃ¼hrt zu prÃ¤ziseren und relevanteren Query-Varianten\n",
    "\n",
    "**Wann Custom Prompt verwenden?**\n",
    "- Spezielle **FachdomÃ¤ne** (z.B. Medizin, Recht, Energie, Technik)\n",
    "- Wenn du **bekannte Synonyme** in der DomÃ¤ne hast\n",
    "- Wenn Standard-Queries zu **generisch** sind\n",
    "- Kontrolle Ã¼ber **Anzahl und Stil** der generierten Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 5: Verschiedene Queries testen\n",
    "\n",
    "Probiere Query Expansion mit verschiedenen Arten von Fragen aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query_expansion(query_text: str, retriever=multi_query_retriever):\n",
    "    \"\"\"Helper function to test a query with expansion\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Single query\n",
    "    single_results = vector_store.similarity_search(query_text, k=5)\n",
    "    print(f\"OHNE Expansion: {len(single_results)} Dokumente\")\n",
    "    for doc in single_results[:3]:  # Zeige nur top 3\n",
    "        print(f\"  - {doc.metadata['title']}\")\n",
    "    if len(single_results) > 3:\n",
    "        print(f\"  ... und {len(single_results) - 3} weitere\")\n",
    "    \n",
    "    # Multi query\n",
    "    print(\"\\nâ³ MIT Expansion...\\n\")\n",
    "    multi_results = retriever.invoke(query_text)\n",
    "    print(f\"\\nMIT Expansion: {len(multi_results)} Dokumente\")\n",
    "    \n",
    "    # Gruppiere nach Artikel-Titel\n",
    "    articles = {}\n",
    "    for doc in multi_results:\n",
    "        title = doc.metadata['title']\n",
    "        if title not in articles:\n",
    "            articles[title] = []\n",
    "        articles[title].append(doc)\n",
    "    \n",
    "    for title, docs in list(articles.items())[:5]:  # Zeige top 5 Artikel\n",
    "        print(f\"  - {title} ({len(docs)} chunks)\")\n",
    "    if len(articles) > 5:\n",
    "        print(f\"  ... und {len(articles) - 5} weitere Artikel\")\n",
    "    \n",
    "    # Comparison\n",
    "    improvement = len(multi_results) - len(single_results)\n",
    "    print(f\"\\nðŸ“Š Unterschied: {improvement:+d} Dokumente ({improvement / len(single_results) * 100:.0f}% mehr)\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "# Test verschiedene Queries\n",
    "test_queries = [\n",
    "    \"climate change impact\",\n",
    "    \"solar power technology\",\n",
    "    \"fossil fuel alternatives\",\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    test_query_expansion(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration in dein RAG-System\n",
    "\n",
    "Du hast bereits eine Custom Query Expansion Implementierung in [query_expansion_retriever.py](../src/advanced_rag/backend/nodes/query_expansion_retriever.py).\n",
    "\n",
    "### Unterschied: Custom Implementation vs. MultiQueryRetriever\n",
    "\n",
    "**Deine Custom Implementation:**\n",
    "```python\n",
    "class QueryExpansionRetriever(BaseNode):\n",
    "    - Nutzt structured output (Pydantic) fÃ¼r Query-Generierung\n",
    "    - Integriert in dein State-Management\n",
    "    - Custom Prompt aus query_expansion_prompt.py\n",
    "    - Deduplizierung mit _unique_documents()\n",
    "```\n",
    "\n",
    "**LangChain MultiQueryRetriever:**\n",
    "```python\n",
    "MultiQueryRetriever.from_llm()\n",
    "    - Standard LangChain Komponente\n",
    "    - Einfacher zu verwenden\n",
    "    - Automatische Deduplizierung\n",
    "    - Logging integriert\n",
    "```\n",
    "\n",
    "### Empfehlung:\n",
    "\n",
    "Behalte deine Custom Implementation, weil:\n",
    "- âœ… Sie bereits in dein System integriert ist\n",
    "- âœ… Du volle Kontrolle Ã¼ber das Prompt hast\n",
    "- âœ… Structured Output ist robuster als String Parsing\n",
    "- âœ… Sie mit deinem State-Management funktioniert\n",
    "\n",
    "Du kannst aber Ideen aus dem MultiQueryRetriever Ã¼bernehmen:\n",
    "- Logging der generierten Queries\n",
    "- Alternative Deduplizierungs-Strategien\n",
    "- Fehlerbehandlung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ãœbung: Query Expansion aktivieren und evaluieren\n",
    "\n",
    "### Schritt 1: Query Expansion im RAG-System aktivieren\n",
    "\n",
    "Ã–ffne [query_routing_graph.py](../src/advanced_rag/backend/graphs/query_routing_graph.py) und aktiviere den QueryExpansionRetriever als Retriever-Option.\n",
    "\n",
    "### Schritt 2: Backend starten\n",
    "\n",
    "```bash\n",
    "uv run --env-file .env python -m src.advanced_rag.backend.main\n",
    "```\n",
    "\n",
    "### Schritt 3: Im Frontend testen\n",
    "\n",
    "Teste mit kurzen, unprÃ¤zisen Queries wie:\n",
    "- \"andrena methoden\"\n",
    "- \"team entwicklung\"\n",
    "- \"agile praktiken\"\n",
    "\n",
    "### Schritt 4: Evaluation durchfÃ¼hren\n",
    "\n",
    "FÃ¼hre eine systematische Evaluation durch:\n",
    "\n",
    "**OHNE Query Expansion:**\n",
    "```bash\n",
    "# Deaktiviere Query Expansion im Graph\n",
    "uv run --env-file .env python src/advanced_rag/evaluation/evaluate_dataset.py\n",
    "```\n",
    "\n",
    "**MIT Query Expansion:**\n",
    "```bash\n",
    "# Aktiviere Query Expansion im Graph\n",
    "uv run --env-file .env python src/advanced_rag/evaluation/evaluate_dataset.py\n",
    "```\n",
    "\n",
    "### Schritt 5: Metriken vergleichen\n",
    "\n",
    "Schaue in Langfuse und vergleiche:\n",
    "\n",
    "| Metrik              | OHNE Query Expansion | MIT Query Expansion | Verbesserung |\n",
    "|---------------------|----------------------|---------------------|---------------|\n",
    "| Context Precision   |          ?           |          ?          |      ?%       |\n",
    "| Context Recall      |          ?           |          ?          |      ?%       |\n",
    "| Answer Relevancy    |          ?           |          ?          |      ?%       |\n",
    "| Faithfulness        |          ?           |          ?          |      ?%       |\n",
    "\n",
    "### Erwartete Ergebnisse:\n",
    "\n",
    "**Context Recall sollte steigen:**\n",
    "- Query Expansion findet mehr relevante Dokumente durch verschiedene Formulierungen\n",
    "\n",
    "**Context Precision kÃ¶nnte leicht sinken:**\n",
    "- Mehr Dokumente bedeuten auch mehr Chance fÃ¼r irrelevante Treffer\n",
    "\n",
    "**Answer Relevancy sollte steigen:**\n",
    "- Breiterer Context ermÃ¶glicht umfassendere Antworten\n",
    "\n",
    "**Trade-off beachten:**\n",
    "- HÃ¶here Kosten (mehr LLM-Calls)\n",
    "- HÃ¶here Latenz (Query-Generierung + mehrere Retrievals)\n",
    "- Aber bessere Abdeckung bei komplexen Fragen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kombination: Query Expansion + Reranking\n",
    "\n",
    "Die **optimale Pipeline** kombiniert beide Techniken:\n",
    "\n",
    "```\n",
    "User Query\n",
    "    â†“\n",
    "Query Expansion (generiere 4-5 Varianten)\n",
    "    â†“\n",
    "Initial Retrieval (k=10 pro Query = 40-50 Kandidaten)\n",
    "    â†“\n",
    "Deduplizierung (einzigartige Dokumente)\n",
    "    â†“\n",
    "Reranking mit CrossEncoder (sortiere nach Relevanz)\n",
    "    â†“\n",
    "Top-K Selection (z.B. beste 5 Dokumente)\n",
    "    â†“\n",
    "LLM Generation\n",
    "```\n",
    "\n",
    "### Vorteile der Kombination:\n",
    "\n",
    "**Query Expansion:**\n",
    "- âœ… HÃ¶herer **Recall** (findet mehr relevante Dokumente)\n",
    "- âœ… Robuster gegenÃ¼ber **unprÃ¤zisen Queries**\n",
    "\n",
    "**Reranking:**\n",
    "- âœ… HÃ¶here **Precision** (sortiert irrelevante Dokumente aus)\n",
    "- âœ… Bessere **semantische Relevanz**\n",
    "\n",
    "**Zusammen:**\n",
    "- âœ… **Hoher Recall UND hohe Precision**\n",
    "- âœ… Robust gegen verschiedene Query-Formulierungen\n",
    "- âœ… Beste Dokumente landen im Context\n",
    "- âŒ HÃ¶here Kosten und Latenz\n",
    "\n",
    "### Implementation:\n",
    "\n",
    "Erweitere deinen QueryExpansionRetriever:\n",
    "\n",
    "```python\n",
    "class QueryExpansionWithRerankingRetriever(BaseNode):\n",
    "    def __init__(self, llm, vector_store, cross_encoder):\n",
    "        self.llm = llm\n",
    "        self.vector_store = vector_store\n",
    "        self.cross_encoder = cross_encoder\n",
    "    \n",
    "    def traverse(self, state: State) -> State:\n",
    "        original_query = state.get_current_question()\n",
    "        \n",
    "        # 1. Expand queries\n",
    "        expanded_queries = self._expand_queries(original_query)\n",
    "        \n",
    "        # 2. Retrieve with all queries\n",
    "        documents = self.retrieve_documents_from(expanded_queries)\n",
    "        \n",
    "        # 3. Rerank with CrossEncoder\n",
    "        reranked_documents = self._rerank(original_query, documents)\n",
    "        \n",
    "        # 4. Keep top-k\n",
    "        state.context = reranked_documents[:CONTEXT_SIZE_AFTER_RERANKING]\n",
    "        return state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "### Was hast du gelernt?\n",
    "\n",
    "1. **Query Expansion verbessert Recall:**\n",
    "   - Generiert automatisch mehrere Formulierungen einer Query\n",
    "   - Findet Dokumente mit verschiedenen Begriffen und Synonymen\n",
    "   - Robuster gegenÃ¼ber unprÃ¤zisen Nutzer-Fragen\n",
    "\n",
    "2. **LangChain MultiQueryRetriever:**\n",
    "   - Einfache Integration mit `.from_llm()`\n",
    "   - Automatische Deduplizierung\n",
    "   - Anpassbar mit Custom Prompts\n",
    "\n",
    "3. **Custom Prompts wichtig fÃ¼r:**\n",
    "   - Domain-spezifische Anwendungen\n",
    "   - Nicht-englische Sprachen\n",
    "   - Kontrolle Ã¼ber Stil und Anzahl der Queries\n",
    "\n",
    "4. **Trade-offs beachten:**\n",
    "   - HÃ¶here Kosten (LLM-Call + mehrere Retrievals)\n",
    "   - HÃ¶here Latenz\n",
    "   - Aber deutlich bessere Abdeckung\n",
    "\n",
    "5. **Best Practice: Kombination mit Reranking**\n",
    "   - Query Expansion fÃ¼r hohen Recall\n",
    "   - Reranking fÃ¼r hohe Precision\n",
    "   - Beste Ergebnisse bei komplexen Queries\n",
    "\n",
    "### NÃ¤chste Schritte:\n",
    "\n",
    "- âœ… Teste Query Expansion in deinem RAG-System\n",
    "- âœ… Evaluiere mit echten Test-Queries\n",
    "- âœ… Experimentiere mit Custom Prompts fÃ¼r deine DomÃ¤ne\n",
    "- âœ… Kombiniere mit Reranking fÃ¼r optimale Ergebnisse\n",
    "- âœ… Monitore Kosten und Latenz in Produktion\n",
    "\n",
    "Viel Erfolg beim Optimieren deines RAG-Systems! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
